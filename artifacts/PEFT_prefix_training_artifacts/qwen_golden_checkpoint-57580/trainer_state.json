{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 57580,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1736714136853074,
      "grad_norm": 2.4281535148620605,
      "learning_rate": 1.9826328586314695e-05,
      "loss": 9.8272,
      "step": 500
    },
    {
      "epoch": 0.3473428273706148,
      "grad_norm": 3.6035799980163574,
      "learning_rate": 1.9652657172629385e-05,
      "loss": 7.1491,
      "step": 1000
    },
    {
      "epoch": 0.5210142410559222,
      "grad_norm": 1.5573837757110596,
      "learning_rate": 1.947898575894408e-05,
      "loss": 5.4246,
      "step": 1500
    },
    {
      "epoch": 0.6946856547412296,
      "grad_norm": 1.313305139541626,
      "learning_rate": 1.9305314345258772e-05,
      "loss": 4.2492,
      "step": 2000
    },
    {
      "epoch": 0.868357068426537,
      "grad_norm": 1.1556980609893799,
      "learning_rate": 1.9131642931573466e-05,
      "loss": 3.6812,
      "step": 2500
    },
    {
      "epoch": 1.0420284821118444,
      "grad_norm": 0.9203393459320068,
      "learning_rate": 1.8957971517888156e-05,
      "loss": 3.1813,
      "step": 3000
    },
    {
      "epoch": 1.2156998957971519,
      "grad_norm": 0.9054070711135864,
      "learning_rate": 1.878430010420285e-05,
      "loss": 2.9903,
      "step": 3500
    },
    {
      "epoch": 1.3893713094824591,
      "grad_norm": 0.904894232749939,
      "learning_rate": 1.8610628690517543e-05,
      "loss": 2.9061,
      "step": 4000
    },
    {
      "epoch": 1.5630427231677666,
      "grad_norm": 0.7161256074905396,
      "learning_rate": 1.8436957276832233e-05,
      "loss": 2.7722,
      "step": 4500
    },
    {
      "epoch": 1.7367141368530739,
      "grad_norm": 2.186903715133667,
      "learning_rate": 1.8263285863146927e-05,
      "loss": 2.676,
      "step": 5000
    },
    {
      "epoch": 1.9103855505383813,
      "grad_norm": 1.172325611114502,
      "learning_rate": 1.808961444946162e-05,
      "loss": 2.5144,
      "step": 5500
    },
    {
      "epoch": 2.084056964223689,
      "grad_norm": 0.9452099204063416,
      "learning_rate": 1.7915943035776314e-05,
      "loss": 2.4721,
      "step": 6000
    },
    {
      "epoch": 2.2577283779089963,
      "grad_norm": 0.7847731113433838,
      "learning_rate": 1.7742271622091004e-05,
      "loss": 2.4649,
      "step": 6500
    },
    {
      "epoch": 2.4313997915943037,
      "grad_norm": 0.6874641180038452,
      "learning_rate": 1.7568600208405697e-05,
      "loss": 2.4464,
      "step": 7000
    },
    {
      "epoch": 2.605071205279611,
      "grad_norm": 0.735504150390625,
      "learning_rate": 1.739492879472039e-05,
      "loss": 2.452,
      "step": 7500
    },
    {
      "epoch": 2.7787426189649183,
      "grad_norm": 1.3226271867752075,
      "learning_rate": 1.7221257381035084e-05,
      "loss": 2.4732,
      "step": 8000
    },
    {
      "epoch": 2.9524140326502257,
      "grad_norm": 0.6354401707649231,
      "learning_rate": 1.7047585967349774e-05,
      "loss": 2.4396,
      "step": 8500
    },
    {
      "epoch": 3.126085446335533,
      "grad_norm": 0.6696029901504517,
      "learning_rate": 1.6873914553664468e-05,
      "loss": 2.3193,
      "step": 9000
    },
    {
      "epoch": 3.2997568600208407,
      "grad_norm": 0.7037970423698425,
      "learning_rate": 1.670024313997916e-05,
      "loss": 2.323,
      "step": 9500
    },
    {
      "epoch": 3.473428273706148,
      "grad_norm": 0.347605437040329,
      "learning_rate": 1.6526571726293855e-05,
      "loss": 2.2924,
      "step": 10000
    },
    {
      "epoch": 3.6470996873914556,
      "grad_norm": 6.768415451049805,
      "learning_rate": 1.6352900312608545e-05,
      "loss": 2.2686,
      "step": 10500
    },
    {
      "epoch": 3.8207711010767627,
      "grad_norm": 1.0599365234375,
      "learning_rate": 1.617922889892324e-05,
      "loss": 2.2509,
      "step": 11000
    },
    {
      "epoch": 3.99444251476207,
      "grad_norm": 2.879890203475952,
      "learning_rate": 1.6005557485237932e-05,
      "loss": 2.2201,
      "step": 11500
    },
    {
      "epoch": 4.168113928447378,
      "grad_norm": 0.43392714858055115,
      "learning_rate": 1.5831886071552625e-05,
      "loss": 2.2101,
      "step": 12000
    },
    {
      "epoch": 4.341785342132685,
      "grad_norm": 2.4970760345458984,
      "learning_rate": 1.5658214657867316e-05,
      "loss": 2.2061,
      "step": 12500
    },
    {
      "epoch": 4.5154567558179926,
      "grad_norm": 1.2098720073699951,
      "learning_rate": 1.548454324418201e-05,
      "loss": 2.1409,
      "step": 13000
    },
    {
      "epoch": 4.6891281695033,
      "grad_norm": 0.4569298028945923,
      "learning_rate": 1.53108718304967e-05,
      "loss": 2.2088,
      "step": 13500
    },
    {
      "epoch": 4.8627995831886075,
      "grad_norm": 0.40268492698669434,
      "learning_rate": 1.5137200416811394e-05,
      "loss": 2.2542,
      "step": 14000
    },
    {
      "epoch": 5.0364709968739145,
      "grad_norm": 0.2928532660007477,
      "learning_rate": 1.4963529003126088e-05,
      "loss": 2.2455,
      "step": 14500
    },
    {
      "epoch": 5.210142410559222,
      "grad_norm": 0.8775211572647095,
      "learning_rate": 1.478985758944078e-05,
      "loss": 2.1158,
      "step": 15000
    },
    {
      "epoch": 5.3838138242445295,
      "grad_norm": 0.3211512863636017,
      "learning_rate": 1.4616186175755472e-05,
      "loss": 2.157,
      "step": 15500
    },
    {
      "epoch": 5.5574852379298365,
      "grad_norm": 0.7289881110191345,
      "learning_rate": 1.4442514762070163e-05,
      "loss": 2.0616,
      "step": 16000
    },
    {
      "epoch": 5.731156651615144,
      "grad_norm": 0.6742651462554932,
      "learning_rate": 1.4268843348384857e-05,
      "loss": 2.0871,
      "step": 16500
    },
    {
      "epoch": 5.9048280653004515,
      "grad_norm": 0.2669638991355896,
      "learning_rate": 1.409517193469955e-05,
      "loss": 2.0884,
      "step": 17000
    },
    {
      "epoch": 6.078499478985759,
      "grad_norm": 5.237482070922852,
      "learning_rate": 1.3921500521014242e-05,
      "loss": 2.1081,
      "step": 17500
    },
    {
      "epoch": 6.252170892671066,
      "grad_norm": 2.4225876331329346,
      "learning_rate": 1.3747829107328934e-05,
      "loss": 2.1289,
      "step": 18000
    },
    {
      "epoch": 6.425842306356373,
      "grad_norm": 1.0774422883987427,
      "learning_rate": 1.3574157693643627e-05,
      "loss": 2.0437,
      "step": 18500
    },
    {
      "epoch": 6.599513720041681,
      "grad_norm": 0.6825706362724304,
      "learning_rate": 1.3400486279958321e-05,
      "loss": 2.0397,
      "step": 19000
    },
    {
      "epoch": 6.773185133726988,
      "grad_norm": 2.095310926437378,
      "learning_rate": 1.3226814866273013e-05,
      "loss": 2.053,
      "step": 19500
    },
    {
      "epoch": 6.946856547412296,
      "grad_norm": 0.3701629340648651,
      "learning_rate": 1.3053143452587705e-05,
      "loss": 2.045,
      "step": 20000
    },
    {
      "epoch": 7.120527961097603,
      "grad_norm": 0.9476151466369629,
      "learning_rate": 1.2879472038902398e-05,
      "loss": 1.9876,
      "step": 20500
    },
    {
      "epoch": 7.29419937478291,
      "grad_norm": 0.7195835709571838,
      "learning_rate": 1.270580062521709e-05,
      "loss": 2.0191,
      "step": 21000
    },
    {
      "epoch": 7.467870788468218,
      "grad_norm": 0.3125503659248352,
      "learning_rate": 1.2532129211531783e-05,
      "loss": 2.0682,
      "step": 21500
    },
    {
      "epoch": 7.641542202153525,
      "grad_norm": 0.8739573955535889,
      "learning_rate": 1.2358457797846475e-05,
      "loss": 2.0602,
      "step": 22000
    },
    {
      "epoch": 7.815213615838833,
      "grad_norm": 1.070502519607544,
      "learning_rate": 1.2184786384161169e-05,
      "loss": 2.0373,
      "step": 22500
    },
    {
      "epoch": 7.98888502952414,
      "grad_norm": 1.2263927459716797,
      "learning_rate": 1.201111497047586e-05,
      "loss": 1.9906,
      "step": 23000
    },
    {
      "epoch": 8.162556443209448,
      "grad_norm": 1.418555736541748,
      "learning_rate": 1.1837443556790554e-05,
      "loss": 1.9155,
      "step": 23500
    },
    {
      "epoch": 8.336227856894755,
      "grad_norm": 0.34032559394836426,
      "learning_rate": 1.1663772143105246e-05,
      "loss": 1.9862,
      "step": 24000
    },
    {
      "epoch": 8.509899270580062,
      "grad_norm": 0.5117616653442383,
      "learning_rate": 1.1490100729419938e-05,
      "loss": 1.8797,
      "step": 24500
    },
    {
      "epoch": 8.68357068426537,
      "grad_norm": 0.5648301243782043,
      "learning_rate": 1.1316429315734631e-05,
      "loss": 2.0196,
      "step": 25000
    },
    {
      "epoch": 8.857242097950678,
      "grad_norm": 0.5965723395347595,
      "learning_rate": 1.1142757902049323e-05,
      "loss": 2.0803,
      "step": 25500
    },
    {
      "epoch": 9.030913511635985,
      "grad_norm": 0.9973442554473877,
      "learning_rate": 1.0969086488364016e-05,
      "loss": 2.0325,
      "step": 26000
    },
    {
      "epoch": 9.204584925321292,
      "grad_norm": 0.2841283082962036,
      "learning_rate": 1.0795415074678708e-05,
      "loss": 2.0008,
      "step": 26500
    },
    {
      "epoch": 9.3782563390066,
      "grad_norm": 0.8814032673835754,
      "learning_rate": 1.0621743660993402e-05,
      "loss": 1.8912,
      "step": 27000
    },
    {
      "epoch": 9.551927752691906,
      "grad_norm": 0.3007594048976898,
      "learning_rate": 1.0448072247308094e-05,
      "loss": 2.0048,
      "step": 27500
    },
    {
      "epoch": 9.725599166377215,
      "grad_norm": 1.104306697845459,
      "learning_rate": 1.0274400833622787e-05,
      "loss": 2.0654,
      "step": 28000
    },
    {
      "epoch": 9.899270580062522,
      "grad_norm": 0.19176997244358063,
      "learning_rate": 1.0100729419937479e-05,
      "loss": 1.9107,
      "step": 28500
    },
    {
      "epoch": 10.072941993747829,
      "grad_norm": 0.2658020555973053,
      "learning_rate": 9.92705800625217e-06,
      "loss": 1.9579,
      "step": 29000
    },
    {
      "epoch": 10.246613407433136,
      "grad_norm": 0.38736292719841003,
      "learning_rate": 9.753386592566864e-06,
      "loss": 2.0266,
      "step": 29500
    },
    {
      "epoch": 10.420284821118443,
      "grad_norm": 0.9151233434677124,
      "learning_rate": 9.579715178881556e-06,
      "loss": 1.8812,
      "step": 30000
    },
    {
      "epoch": 10.593956234803752,
      "grad_norm": 0.32754433155059814,
      "learning_rate": 9.40604376519625e-06,
      "loss": 1.971,
      "step": 30500
    },
    {
      "epoch": 10.767627648489059,
      "grad_norm": 0.6150321364402771,
      "learning_rate": 9.232372351510941e-06,
      "loss": 1.891,
      "step": 31000
    },
    {
      "epoch": 10.941299062174366,
      "grad_norm": 0.34028056263923645,
      "learning_rate": 9.058700937825635e-06,
      "loss": 1.9142,
      "step": 31500
    },
    {
      "epoch": 11.114970475859673,
      "grad_norm": 0.31324657797813416,
      "learning_rate": 8.885029524140327e-06,
      "loss": 1.9748,
      "step": 32000
    },
    {
      "epoch": 11.28864188954498,
      "grad_norm": 0.21245735883712769,
      "learning_rate": 8.711358110455018e-06,
      "loss": 1.8424,
      "step": 32500
    },
    {
      "epoch": 11.462313303230289,
      "grad_norm": 0.26598697900772095,
      "learning_rate": 8.537686696769712e-06,
      "loss": 1.9482,
      "step": 33000
    },
    {
      "epoch": 11.635984716915596,
      "grad_norm": 1.5246742963790894,
      "learning_rate": 8.364015283084404e-06,
      "loss": 1.9397,
      "step": 33500
    },
    {
      "epoch": 11.809656130600903,
      "grad_norm": 1.4634627103805542,
      "learning_rate": 8.190343869399097e-06,
      "loss": 1.9323,
      "step": 34000
    },
    {
      "epoch": 11.98332754428621,
      "grad_norm": 0.30295154452323914,
      "learning_rate": 8.016672455713789e-06,
      "loss": 1.9739,
      "step": 34500
    },
    {
      "epoch": 12.156998957971519,
      "grad_norm": 0.18747010827064514,
      "learning_rate": 7.843001042028483e-06,
      "loss": 1.8877,
      "step": 35000
    },
    {
      "epoch": 12.330670371656826,
      "grad_norm": 0.2708038091659546,
      "learning_rate": 7.669329628343174e-06,
      "loss": 1.9195,
      "step": 35500
    },
    {
      "epoch": 12.504341785342133,
      "grad_norm": 0.8927952647209167,
      "learning_rate": 7.495658214657868e-06,
      "loss": 1.9261,
      "step": 36000
    },
    {
      "epoch": 12.67801319902744,
      "grad_norm": 0.3530200123786926,
      "learning_rate": 7.321986800972561e-06,
      "loss": 1.9115,
      "step": 36500
    },
    {
      "epoch": 12.851684612712747,
      "grad_norm": 1.0452207326889038,
      "learning_rate": 7.148315387287253e-06,
      "loss": 1.9624,
      "step": 37000
    },
    {
      "epoch": 13.025356026398056,
      "grad_norm": 2.17965030670166,
      "learning_rate": 6.974643973601946e-06,
      "loss": 1.9962,
      "step": 37500
    },
    {
      "epoch": 13.199027440083363,
      "grad_norm": 1.0872936248779297,
      "learning_rate": 6.800972559916639e-06,
      "loss": 1.9258,
      "step": 38000
    },
    {
      "epoch": 13.37269885376867,
      "grad_norm": 0.5572669506072998,
      "learning_rate": 6.62730114623133e-06,
      "loss": 1.8343,
      "step": 38500
    },
    {
      "epoch": 13.546370267453977,
      "grad_norm": 0.17933085560798645,
      "learning_rate": 6.453629732546024e-06,
      "loss": 1.8328,
      "step": 39000
    },
    {
      "epoch": 13.720041681139284,
      "grad_norm": 0.4177659749984741,
      "learning_rate": 6.279958318860716e-06,
      "loss": 1.8736,
      "step": 39500
    },
    {
      "epoch": 13.893713094824593,
      "grad_norm": 0.4060109555721283,
      "learning_rate": 6.106286905175408e-06,
      "loss": 2.0237,
      "step": 40000
    },
    {
      "epoch": 14.0673845085099,
      "grad_norm": 0.1912304311990738,
      "learning_rate": 5.932615491490101e-06,
      "loss": 1.909,
      "step": 40500
    },
    {
      "epoch": 14.241055922195207,
      "grad_norm": 1.0773836374282837,
      "learning_rate": 5.758944077804794e-06,
      "loss": 1.9205,
      "step": 41000
    },
    {
      "epoch": 14.414727335880514,
      "grad_norm": 0.24477176368236542,
      "learning_rate": 5.585272664119486e-06,
      "loss": 1.9116,
      "step": 41500
    },
    {
      "epoch": 14.58839874956582,
      "grad_norm": 0.5534825921058655,
      "learning_rate": 5.411601250434179e-06,
      "loss": 1.8513,
      "step": 42000
    },
    {
      "epoch": 14.76207016325113,
      "grad_norm": 0.6509454846382141,
      "learning_rate": 5.237929836748872e-06,
      "loss": 1.7778,
      "step": 42500
    },
    {
      "epoch": 14.935741576936437,
      "grad_norm": 0.2655586004257202,
      "learning_rate": 5.0642584230635635e-06,
      "loss": 1.9218,
      "step": 43000
    },
    {
      "epoch": 15.109412990621744,
      "grad_norm": 0.2537062168121338,
      "learning_rate": 4.890587009378256e-06,
      "loss": 1.9714,
      "step": 43500
    },
    {
      "epoch": 15.28308440430705,
      "grad_norm": 0.29708370566368103,
      "learning_rate": 4.716915595692949e-06,
      "loss": 1.7821,
      "step": 44000
    },
    {
      "epoch": 15.456755817992358,
      "grad_norm": 0.25830695033073425,
      "learning_rate": 4.5432441820076414e-06,
      "loss": 1.8751,
      "step": 44500
    },
    {
      "epoch": 15.630427231677666,
      "grad_norm": 0.21036408841609955,
      "learning_rate": 4.369572768322334e-06,
      "loss": 1.9515,
      "step": 45000
    },
    {
      "epoch": 15.804098645362973,
      "grad_norm": 0.8511738777160645,
      "learning_rate": 4.195901354637027e-06,
      "loss": 1.8679,
      "step": 45500
    },
    {
      "epoch": 15.97777005904828,
      "grad_norm": 1.080995798110962,
      "learning_rate": 4.022229940951719e-06,
      "loss": 1.9551,
      "step": 46000
    },
    {
      "epoch": 16.151441472733588,
      "grad_norm": 1.001132607460022,
      "learning_rate": 3.848558527266412e-06,
      "loss": 1.887,
      "step": 46500
    },
    {
      "epoch": 16.325112886418896,
      "grad_norm": 0.6061681509017944,
      "learning_rate": 3.6748871135811047e-06,
      "loss": 1.8413,
      "step": 47000
    },
    {
      "epoch": 16.4987843001042,
      "grad_norm": 0.14408814907073975,
      "learning_rate": 3.5012156998957974e-06,
      "loss": 1.8604,
      "step": 47500
    },
    {
      "epoch": 16.67245571378951,
      "grad_norm": 0.26100966334342957,
      "learning_rate": 3.32754428621049e-06,
      "loss": 1.8409,
      "step": 48000
    },
    {
      "epoch": 16.84612712747482,
      "grad_norm": 0.22107410430908203,
      "learning_rate": 3.1538728725251827e-06,
      "loss": 2.0002,
      "step": 48500
    },
    {
      "epoch": 17.019798541160124,
      "grad_norm": 0.2393590658903122,
      "learning_rate": 2.9802014588398754e-06,
      "loss": 1.924,
      "step": 49000
    },
    {
      "epoch": 17.193469954845433,
      "grad_norm": 0.4666116237640381,
      "learning_rate": 2.806530045154568e-06,
      "loss": 1.8835,
      "step": 49500
    },
    {
      "epoch": 17.36714136853074,
      "grad_norm": 0.8151688575744629,
      "learning_rate": 2.6328586314692607e-06,
      "loss": 1.9176,
      "step": 50000
    },
    {
      "epoch": 17.540812782216047,
      "grad_norm": 0.35729777812957764,
      "learning_rate": 2.459187217783953e-06,
      "loss": 1.7709,
      "step": 50500
    },
    {
      "epoch": 17.714484195901356,
      "grad_norm": 0.2826596796512604,
      "learning_rate": 2.2855158040986456e-06,
      "loss": 1.8882,
      "step": 51000
    },
    {
      "epoch": 17.88815560958666,
      "grad_norm": 0.20159366726875305,
      "learning_rate": 2.1118443904133382e-06,
      "loss": 1.8413,
      "step": 51500
    },
    {
      "epoch": 18.06182702327197,
      "grad_norm": 0.3046313524246216,
      "learning_rate": 1.938172976728031e-06,
      "loss": 1.9982,
      "step": 52000
    },
    {
      "epoch": 18.235498436957275,
      "grad_norm": 0.3096620440483093,
      "learning_rate": 1.7645015630427233e-06,
      "loss": 1.8116,
      "step": 52500
    },
    {
      "epoch": 18.409169850642584,
      "grad_norm": 0.17968380451202393,
      "learning_rate": 1.590830149357416e-06,
      "loss": 1.9541,
      "step": 53000
    },
    {
      "epoch": 18.582841264327893,
      "grad_norm": 0.6838036179542542,
      "learning_rate": 1.4171587356721085e-06,
      "loss": 1.9079,
      "step": 53500
    },
    {
      "epoch": 18.7565126780132,
      "grad_norm": 0.36351773142814636,
      "learning_rate": 1.2434873219868011e-06,
      "loss": 1.9241,
      "step": 54000
    },
    {
      "epoch": 18.930184091698507,
      "grad_norm": 0.44468235969543457,
      "learning_rate": 1.0698159083014936e-06,
      "loss": 1.8809,
      "step": 54500
    },
    {
      "epoch": 19.103855505383812,
      "grad_norm": 0.1504354178905487,
      "learning_rate": 8.961444946161862e-07,
      "loss": 1.8008,
      "step": 55000
    },
    {
      "epoch": 19.27752691906912,
      "grad_norm": 0.6608782410621643,
      "learning_rate": 7.224730809308789e-07,
      "loss": 1.8138,
      "step": 55500
    },
    {
      "epoch": 19.45119833275443,
      "grad_norm": 0.2274169921875,
      "learning_rate": 5.488016672455714e-07,
      "loss": 1.9079,
      "step": 56000
    },
    {
      "epoch": 19.624869746439735,
      "grad_norm": 0.17314982414245605,
      "learning_rate": 3.7513025356026403e-07,
      "loss": 1.9414,
      "step": 56500
    },
    {
      "epoch": 19.798541160125044,
      "grad_norm": 0.3258104622364044,
      "learning_rate": 2.014588398749566e-07,
      "loss": 1.8752,
      "step": 57000
    },
    {
      "epoch": 19.97221257381035,
      "grad_norm": 0.2327369600534439,
      "learning_rate": 2.7787426189649184e-08,
      "loss": 1.9013,
      "step": 57500
    }
  ],
  "logging_steps": 500,
  "max_steps": 57580,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0310634919080223e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
