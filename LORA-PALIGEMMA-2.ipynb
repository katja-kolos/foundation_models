{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb34affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use only GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "616c9e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA memory cleared.\n",
      "Allocated memory: 0 bytes\n",
      "Cached memory: 0 bytes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Clear all cached memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Reset all allocated memory\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "# If you want to reset the default CUDA device, you can specify it again\n",
    "torch.cuda.set_device(0)  # Replace 0 with the desired GPU index if needed\n",
    "\n",
    "# Print memory stats to confirm\n",
    "print(\"CUDA memory cleared.\")\n",
    "print(f\"Allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "print(f\"Cached memory: {torch.cuda.memory_reserved()} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f4f4cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 10 12:44:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:15:00.0 Off |                  Off |\n",
      "| 30%   36C    P8              8W /  300W |      18MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off |   00000000:2D:00.0 Off |                  Off |\n",
      "| 30%   36C    P8              9W /  300W |     111MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      5670      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    1   N/A  N/A      5670      G   /usr/lib/xorg/Xorg                             97MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69b899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()  # Suppress warnings and info logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184db7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "# from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor\n",
    "import gc\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d3181f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_id = \"HuggingFaceM4/ChartQA\"\n",
    "dataset_id = \"derek-thomas/ScienceQA\"\n",
    "#TODO: DON'T FORGET TO HAVE THE ENTIRE DATASET\n",
    "train_dataset, eval_dataset, test_dataset = load_dataset(dataset_id, split=[\"train\", \"validation\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61cbc295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_question_text(problem):\n",
    "    question = problem['question']\n",
    "    return question\n",
    "\n",
    "\n",
    "def get_choice_text(probelm, options):\n",
    "    choices = probelm['choices']\n",
    "    choice_list = []\n",
    "    for i, c in enumerate(choices):\n",
    "        choice_list.append(\"({}) {}\".format(options[i], c))\n",
    "    choice_txt = \" \".join(choice_list)\n",
    "    return choice_txt\n",
    "\n",
    "\n",
    "def get_context_text(problem, use_caption):\n",
    "    txt_context = problem['hint']\n",
    "    img_context = problem['caption'] if use_caption else \"\"\n",
    "    context = \" \".join([txt_context, img_context]).strip()\n",
    "    if context == \"\":\n",
    "        context = \"N/A\"\n",
    "    return context\n",
    "\n",
    "\n",
    "def build_prompt(question_data, use_lecture=False, use_solution=False):\n",
    "    question = get_question_text(question_data)\n",
    "    choices = get_choice_text(question_data, [choice_num for choice_num in range(5)])\n",
    "    hint = get_context_text(question_data, False)\n",
    "    task = question_data['task']\n",
    "    input_prompt = f'Question: {question}\\n Task: {task}\\n Choices: {choices}\\n Hint: {hint}'\n",
    "    if use_lecture:\n",
    "        lecture = f'\\n Lecture: {question_data[\"lecture\"]}'\n",
    "        input_prompt += lecture\n",
    "    if use_solution and question_data[\"solution\"]:\n",
    "        solution = f'\\n Solution: {question_data[\"solution\"]}'\n",
    "        input_prompt += solution\n",
    "    return input_prompt\n",
    "\n",
    "def build_message(row):\n",
    "    row_input = build_prompt(row)\n",
    "    image = row['image'] if row['image'] else Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": row_input },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d154c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.filter(lambda example: example['solution']!=\"\")\n",
    "eval_dataset = eval_dataset.filter(lambda example: example['solution']!=\"\")\n",
    "test_dataset = test_dataset.filter(lambda example: (example['solution']!=\"\") & (example['lecture']!=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc1d1f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "    num_rows: 11515\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f242ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "    num_rows: 3848\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d697c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "    num_rows: 3172\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ea22baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_gemini = pd.read_csv('gemini_1_5_flash_output_train.csv', sep=\"\\t\")[['index', 'input', 'answer', 'explanation']]\n",
    "train_dataset_gemini['solution'] = train_dataset_gemini['explanation']\n",
    "del train_dataset_gemini['explanation']\n",
    "train_dataset_df = pd.DataFrame(train_dataset).reset_index()\n",
    "train_dataset_gemini = pd.merge(train_dataset_gemini, train_dataset_df[['index', 'image']], on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16ce6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset_qwen_gemini = [(sample[1][\"input\"], sample[1][\"solution\"]) for sample in train_dataset_gemini.iterrows()]\n",
    "# train_dataset_qwen = [(build_message(sample), sample[\"solution\"]) for sample in train_dataset]\n",
    "# eval_dataset_qwen = [(build_message(sample), sample[\"solution\"]) for sample in eval_dataset]\n",
    "# test_dataset_qwen = [(build_message(sample), sample[\"solution\"]) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a15c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_paligemma_gemini = [(sample[1][\"input\"], sample[1][\"image\"], sample[1][\"solution\"]) for sample in train_dataset_gemini.iterrows()] # sample[\"input\"] is the output of build_prompt\n",
    "train_dataset_paligemma = [(build_prompt(sample), sample[\"image\"], sample[\"solution\"]) for sample in train_dataset]\n",
    "eval_dataset_paligemma = [(build_prompt(sample), sample[\"image\"], sample[\"solution\"]) for sample in eval_dataset]\n",
    "test_dataset_paligemma = [(build_prompt(sample), sample[\"image\"], sample[\"solution\"]) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abf16781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=750x429>,\n",
       " 'question': 'Which of these states is farthest north?',\n",
       " 'choices': ['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma'],\n",
       " 'answer': 0,\n",
       " 'hint': '',\n",
       " 'task': 'closed choice',\n",
       " 'grade': 'grade2',\n",
       " 'subject': 'social science',\n",
       " 'topic': 'geography',\n",
       " 'category': 'Geography',\n",
       " 'skill': 'Read a map: cardinal directions',\n",
       " 'lecture': 'Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\\nA compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\\nThe north arrow points to the North Pole. On most maps, north is at the top of the map.',\n",
       " 'solution': 'To find the answer, look at the compass rose. Look at which way the north arrow is pointing. West Virginia is farthest north.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ad637ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU allocated memory: 0.00 GB\n",
      "GPU reserved memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "def clear_memory():\n",
    "    # Delete variables if they exist in the current global scope\n",
    "    if \"inputs\" in globals():\n",
    "        del globals()[\"inputs\"]\n",
    "    if \"model\" in globals():\n",
    "        del globals()[\"model\"]\n",
    "    if \"processor\" in globals():\n",
    "        del globals()[\"processor\"]\n",
    "    if \"trainer\" in globals():\n",
    "        del globals()[\"trainer\"]\n",
    "    if \"peft_model\" in globals():\n",
    "        del globals()[\"peft_model\"]\n",
    "    if \"bnb_config\" in globals():\n",
    "        del globals()[\"bnb_config\"]\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Garbage collection and clearing CUDA memory\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    time.sleep(2)\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67131a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 12:45:36.309214: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-10 12:45:36.322251: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736509536.338399  783314 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736509536.343458  783314 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-10 12:45:36.360485: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6976b6abc79b4af786dc0980a1ff59a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import PaliGemmaProcessor, PaliGemmaForConditionalGeneration\n",
    "\n",
    "model_id = \"google/paligemma2-3b-pt-224\"\n",
    "\n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)\n",
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b879cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,592,768 || all params: 3,034,835,184 || trainable%: 0.0854\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Configure LoRA\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Apply PEFT model adaptation\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b32df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: SET EXPERIMENTS IN A LOOP AND MAKE IT RUN BEFORE THE FLIGHT\n",
    "\n",
    "### -> both qwen and paligemma for the normal \"label\" data and the gemini data please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1e8c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "\n",
    "# Configure training arguments\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"LORA-Paligemma-ScienceQA\",  # Directory to save the model\n",
    "    num_train_epochs=10,  # Number of training epochs\n",
    "    per_device_train_batch_size=4,  # Batch size for training\n",
    "    per_device_eval_batch_size=4,  # Batch size for evaluation\n",
    "    gradient_accumulation_steps=8,  # Steps to accumulate gradients\n",
    "    gradient_checkpointing=True,  # Enable gradient checkpointing for memory efficiency\n",
    "    # Optimizer and scheduler settings\n",
    "    optim=\"adamw_torch_fused\",  # Optimizer type\n",
    "    learning_rate=2e-4,  # Learning rate for training\n",
    "    lr_scheduler_type=\"constant\",  # Type of learning rate scheduler\n",
    "    # Logging and evaluation\n",
    "    logging_steps=10,  # Steps interval for logging\n",
    "    eval_steps=10,  # Steps interval for evaluation\n",
    "    eval_strategy=\"steps\",  # Strategy for evaluation\n",
    "    save_strategy=\"steps\",  # Strategy for saving the model\n",
    "    save_steps=20,  # Steps interval for saving\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to evaluate the best model\n",
    "    greater_is_better=False,  # Whether higher metric values are better\n",
    "    load_best_model_at_end=True,  # Load the best model after training\n",
    "    # Mixed precision and gradient settings\n",
    "    bf16=True,  # Use bfloat16 precision\n",
    "    tf32=True,  # Use TensorFloat-32 precision\n",
    "    max_grad_norm=0.3,  # Maximum norm for gradient clipping\n",
    "    warmup_ratio=0.03,  # Ratio of total steps for warmup\n",
    "    # Hub and reporting\n",
    "    push_to_hub=False,  # Whether to push model to Hugging Face Hub\n",
    "    report_to=\"wandb\",  # Reporting tool for tracking metrics\n",
    "    # Gradient checkpointing settings\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},  # Options for gradient checkpointing\n",
    "    # Dataset configuration\n",
    "    dataset_text_field=\"\",  # Text field in dataset\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},  # Additional dataset options\n",
    "    # max_seq_length=1024  # Maximum sequence length for input\n",
    ")\n",
    "\n",
    "training_args.remove_unused_columns = False  # Keep unused columns in dataset\n",
    "training_args.eval_strategy = \"epoch\"\n",
    "training_args.save_strategy = \"epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "888944e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatyashpr\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/lhome/matiada/foundation_models/wandb/run-20250110_124544-so388cf4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matyashpr/LORA-Paligemma-ScienceQA/runs/so388cf4' target=\"_blank\">LORA-Paligemma-ScienceQA</a></strong> to <a href='https://wandb.ai/matyashpr/LORA-Paligemma-ScienceQA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matyashpr/LORA-Paligemma-ScienceQA' target=\"_blank\">https://wandb.ai/matyashpr/LORA-Paligemma-ScienceQA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matyashpr/LORA-Paligemma-ScienceQA/runs/so388cf4' target=\"_blank\">https://wandb.ai/matyashpr/LORA-Paligemma-ScienceQA/runs/so388cf4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/matyashpr/LORA-Paligemma-ScienceQA/runs/so388cf4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x772709624d90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"LORA-Paligemma-ScienceQA\",  # change this\n",
    "    name=\"LORA-Paligemma-ScienceQA\",  # change this\n",
    "    config=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d1d6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data collator to encode text and image pairs\n",
    "def collate_fn_qwen(examples):\n",
    "    \n",
    "    # Get the texts and images, and apply the chat template\n",
    "    texts = [\n",
    "        processor.apply_chat_template(example, tokenize=False) for (example,_) in examples\n",
    "    ]  # Prepare texts for processing\n",
    "    image_inputs = [process_vision_info(example)[0] for (example,_) in examples]  # Process the images to extract inputs\n",
    "\n",
    "    # Tokenize the texts and process the images\n",
    "    batch = processor(\n",
    "        text=texts, images=image_inputs, padding=\"longest\", return_tensors=\"pt\"\n",
    "    ) \n",
    "    max_length = batch[\"input_ids\"].size(1)\n",
    "    example_labels = [label for (x, label) in examples]\n",
    "    labels = tokenizer(example_labels, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    batch[\"labels\"] = labels  # Add labels to the batch\n",
    "    return batch  # Return the prepared batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9dc593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data collator to encode text and image pairs\n",
    "def collate_fn_paligemma(examples):\n",
    "    texts = [text for (text, image, label) in examples]\n",
    "    image_inputs = [image.resize((224, 224)) if image else Image.new(\"RGB\", (224, 224), (0, 0, 0)) for (text, image, label) in examples]\n",
    "\n",
    "    # Tokenize the texts and process the images\n",
    "    batch = processor(\n",
    "        text=texts, images=image_inputs, padding=\"longest\", return_tensors=\"pt\"\n",
    "    )\n",
    "    max_length = batch[\"input_ids\"].size(1)\n",
    "    example_labels = [label for (text, image, label) in examples]\n",
    "    labels = processor.tokenizer(example_labels, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    batch[\"labels\"] = labels  # Add labels to the batch\n",
    "    return batch  # Return the prepared batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5b0bab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_783314/1238818769.py:4: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n",
      "/lhome/matiada/venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_paligemma,\n",
    "    eval_dataset=eval_dataset_paligemma,\n",
    "    data_collator=collate_fn_paligemma,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e07f04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/lhome/matiada/venv/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:134: FutureWarning: The `ignore_index` attribute is deprecated and will be removed in v4.47.\n",
      "  warnings.warn(\n",
      "/lhome/matiada/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 150.7346, 'grad_norm': 245.60951232910156, 'learning_rate': 0.0002, 'epoch': 0.027787426189649182}\n",
      "{'loss': 67.5996, 'grad_norm': 56.05059814453125, 'learning_rate': 0.0002, 'epoch': 0.055574852379298365}\n",
      "{'loss': 42.0873, 'grad_norm': 47.7778434753418, 'learning_rate': 0.0002, 'epoch': 0.08336227856894755}\n",
      "{'loss': 34.7834, 'grad_norm': 24.753293991088867, 'learning_rate': 0.0002, 'epoch': 0.11114970475859673}\n",
      "{'loss': 30.4227, 'grad_norm': 48.8653450012207, 'learning_rate': 0.0002, 'epoch': 0.13893713094824592}\n",
      "{'loss': 26.4546, 'grad_norm': 147.55799865722656, 'learning_rate': 0.0002, 'epoch': 0.1667245571378951}\n",
      "{'loss': 23.7438, 'grad_norm': 71.36222839355469, 'learning_rate': 0.0002, 'epoch': 0.1945119833275443}\n",
      "{'loss': 22.6143, 'grad_norm': 33.79683303833008, 'learning_rate': 0.0002, 'epoch': 0.22229940951719346}\n",
      "{'loss': 21.2488, 'grad_norm': 320.13128662109375, 'learning_rate': 0.0002, 'epoch': 0.25008683570684265}\n",
      "{'loss': 19.7692, 'grad_norm': 108.7056655883789, 'learning_rate': 0.0002, 'epoch': 0.27787426189649184}\n",
      "{'loss': 19.8388, 'grad_norm': 46.9013671875, 'learning_rate': 0.0002, 'epoch': 0.305661688086141}\n",
      "{'loss': 18.522, 'grad_norm': 81.26273345947266, 'learning_rate': 0.0002, 'epoch': 0.3334491142757902}\n",
      "{'loss': 18.2663, 'grad_norm': 68.48158264160156, 'learning_rate': 0.0002, 'epoch': 0.3612365404654394}\n",
      "{'loss': 18.2174, 'grad_norm': 379.4236145019531, 'learning_rate': 0.0002, 'epoch': 0.3890239666550886}\n",
      "{'loss': 17.0113, 'grad_norm': 67.6048583984375, 'learning_rate': 0.0002, 'epoch': 0.4168113928447378}\n",
      "{'loss': 17.2359, 'grad_norm': 101.3963851928711, 'learning_rate': 0.0002, 'epoch': 0.4445988190343869}\n",
      "{'loss': 16.4312, 'grad_norm': 59.03969192504883, 'learning_rate': 0.0002, 'epoch': 0.4723862452240361}\n",
      "{'loss': 16.9602, 'grad_norm': 176.34298706054688, 'learning_rate': 0.0002, 'epoch': 0.5001736714136853}\n",
      "{'loss': 16.9432, 'grad_norm': 93.2895278930664, 'learning_rate': 0.0002, 'epoch': 0.5279610976033345}\n",
      "{'loss': 16.6466, 'grad_norm': 317.83697509765625, 'learning_rate': 0.0002, 'epoch': 0.5557485237929837}\n",
      "{'loss': 16.3401, 'grad_norm': 477.8699645996094, 'learning_rate': 0.0002, 'epoch': 0.5835359499826328}\n",
      "{'loss': 17.6305, 'grad_norm': 297.8430480957031, 'learning_rate': 0.0002, 'epoch': 0.611323376172282}\n",
      "{'loss': 17.1355, 'grad_norm': 36.94834899902344, 'learning_rate': 0.0002, 'epoch': 0.6391108023619312}\n",
      "{'loss': 15.2191, 'grad_norm': 74.7492446899414, 'learning_rate': 0.0002, 'epoch': 0.6668982285515804}\n",
      "{'loss': 15.759, 'grad_norm': 256.5350646972656, 'learning_rate': 0.0002, 'epoch': 0.6946856547412296}\n",
      "{'loss': 15.4092, 'grad_norm': 83.71309661865234, 'learning_rate': 0.0002, 'epoch': 0.7224730809308788}\n",
      "{'loss': 15.5464, 'grad_norm': 228.18173217773438, 'learning_rate': 0.0002, 'epoch': 0.7502605071205279}\n",
      "{'loss': 14.329, 'grad_norm': 52.402435302734375, 'learning_rate': 0.0002, 'epoch': 0.7780479333101772}\n",
      "{'loss': 14.4533, 'grad_norm': 87.88849639892578, 'learning_rate': 0.0002, 'epoch': 0.8058353594998263}\n",
      "{'loss': 13.8782, 'grad_norm': 61.721431732177734, 'learning_rate': 0.0002, 'epoch': 0.8336227856894756}\n",
      "{'loss': 14.7131, 'grad_norm': 180.8353271484375, 'learning_rate': 0.0002, 'epoch': 0.8614102118791247}\n",
      "{'loss': 14.3859, 'grad_norm': 30.70298194885254, 'learning_rate': 0.0002, 'epoch': 0.8891976380687738}\n",
      "{'loss': 15.0048, 'grad_norm': 114.55908966064453, 'learning_rate': 0.0002, 'epoch': 0.9169850642584231}\n",
      "{'loss': 14.22, 'grad_norm': 40.06781005859375, 'learning_rate': 0.0002, 'epoch': 0.9447724904480722}\n",
      "{'loss': 13.6542, 'grad_norm': 74.50560760498047, 'learning_rate': 0.0002, 'epoch': 0.9725599166377215}\n",
      "{'eval_loss': 1.6830719709396362, 'eval_runtime': 169.5598, 'eval_samples_per_second': 22.694, 'eval_steps_per_second': 5.674, 'epoch': 0.9975686002084057}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/matiada/venv/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:134: FutureWarning: The `ignore_index` attribute is deprecated and will be removed in v4.47.\n",
      "  warnings.warn(\n",
      "/lhome/matiada/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.0793, 'grad_norm': 81.245361328125, 'learning_rate': 0.0002, 'epoch': 1.002778742618965}\n",
      "{'loss': 13.463, 'grad_norm': 59.241058349609375, 'learning_rate': 0.0002, 'epoch': 1.030566168808614}\n",
      "{'loss': 13.4047, 'grad_norm': 284.3699645996094, 'learning_rate': 0.0002, 'epoch': 1.0583535949982632}\n",
      "{'loss': 13.2811, 'grad_norm': 96.35693359375, 'learning_rate': 0.0002, 'epoch': 1.0861410211879126}\n",
      "{'loss': 13.4356, 'grad_norm': 82.69366455078125, 'learning_rate': 0.0002, 'epoch': 1.1139284473775617}\n",
      "{'loss': 13.6338, 'grad_norm': 460.0487060546875, 'learning_rate': 0.0002, 'epoch': 1.1417158735672108}\n",
      "{'loss': 13.5995, 'grad_norm': 59.260372161865234, 'learning_rate': 0.0002, 'epoch': 1.16950329975686}\n",
      "{'loss': 13.0844, 'grad_norm': 72.29168701171875, 'learning_rate': 0.0002, 'epoch': 1.1972907259465093}\n",
      "{'loss': 13.0267, 'grad_norm': 50.122657775878906, 'learning_rate': 0.0002, 'epoch': 1.2250781521361584}\n",
      "{'loss': 13.948, 'grad_norm': 165.10292053222656, 'learning_rate': 0.0002, 'epoch': 1.2528655783258076}\n",
      "{'loss': 13.3569, 'grad_norm': 30.3693790435791, 'learning_rate': 0.0002, 'epoch': 1.2806530045154567}\n",
      "{'loss': 14.0256, 'grad_norm': 96.92388153076172, 'learning_rate': 0.0002, 'epoch': 1.3084404307051059}\n",
      "{'loss': 13.5835, 'grad_norm': 304.42547607421875, 'learning_rate': 0.0002, 'epoch': 1.3362278568947552}\n",
      "{'loss': 12.1337, 'grad_norm': 136.22268676757812, 'learning_rate': 0.0002, 'epoch': 1.3640152830844043}\n",
      "{'loss': 12.5012, 'grad_norm': 84.8637924194336, 'learning_rate': 0.0002, 'epoch': 1.3918027092740535}\n",
      "{'loss': 13.6573, 'grad_norm': 105.54871368408203, 'learning_rate': 0.0002, 'epoch': 1.4195901354637026}\n",
      "{'loss': 11.9799, 'grad_norm': 32.36337661743164, 'learning_rate': 0.0002, 'epoch': 1.4473775616533517}\n",
      "{'loss': 13.4133, 'grad_norm': 77.83900451660156, 'learning_rate': 0.0002, 'epoch': 1.475164987843001}\n",
      "{'loss': 13.3869, 'grad_norm': 214.19789123535156, 'learning_rate': 0.0002, 'epoch': 1.5029524140326502}\n",
      "{'loss': 14.0466, 'grad_norm': 98.0925521850586, 'learning_rate': 0.0002, 'epoch': 1.5307398402222994}\n",
      "{'loss': 12.4705, 'grad_norm': 62.32494354248047, 'learning_rate': 0.0002, 'epoch': 1.5585272664119487}\n",
      "{'loss': 12.238, 'grad_norm': 321.7160949707031, 'learning_rate': 0.0002, 'epoch': 1.5863146926015976}\n",
      "{'loss': 12.5919, 'grad_norm': 139.27769470214844, 'learning_rate': 0.0002, 'epoch': 1.614102118791247}\n",
      "{'loss': 13.146, 'grad_norm': 29.166465759277344, 'learning_rate': 0.0002, 'epoch': 1.6418895449808961}\n",
      "{'loss': 12.2484, 'grad_norm': 25.07976722717285, 'learning_rate': 0.0002, 'epoch': 1.6696769711705453}\n",
      "{'loss': 12.0334, 'grad_norm': 29.64433479309082, 'learning_rate': 0.0002, 'epoch': 1.6974643973601946}\n",
      "{'loss': 11.8304, 'grad_norm': 93.78572082519531, 'learning_rate': 0.0002, 'epoch': 1.7252518235498437}\n",
      "{'loss': 12.2906, 'grad_norm': 49.75325012207031, 'learning_rate': 0.0002, 'epoch': 1.7530392497394929}\n",
      "{'loss': 12.0779, 'grad_norm': 76.09095764160156, 'learning_rate': 0.0002, 'epoch': 1.780826675929142}\n",
      "{'loss': 12.6538, 'grad_norm': 343.9725341796875, 'learning_rate': 0.0002, 'epoch': 1.8086141021187911}\n",
      "{'loss': 12.0694, 'grad_norm': 14.561434745788574, 'learning_rate': 0.0002, 'epoch': 1.8364015283084405}\n",
      "{'loss': 11.602, 'grad_norm': 118.52116394042969, 'learning_rate': 0.0002, 'epoch': 1.8641889544980896}\n",
      "{'loss': 11.9562, 'grad_norm': 77.924560546875, 'learning_rate': 0.0002, 'epoch': 1.8919763806877388}\n",
      "{'loss': 11.9009, 'grad_norm': 71.02091217041016, 'learning_rate': 0.0002, 'epoch': 1.9197638068773881}\n",
      "{'loss': 12.6231, 'grad_norm': 76.79801177978516, 'learning_rate': 0.0002, 'epoch': 1.947551233067037}\n",
      "{'loss': 12.3925, 'grad_norm': 318.2550964355469, 'learning_rate': 0.0002, 'epoch': 1.9753386592566864}\n",
      "{'eval_loss': 1.4830206632614136, 'eval_runtime': 169.1968, 'eval_samples_per_second': 22.743, 'eval_steps_per_second': 5.686, 'epoch': 1.9975686002084057}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/matiada/venv/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:134: FutureWarning: The `ignore_index` attribute is deprecated and will be removed in v4.47.\n",
      "  warnings.warn(\n",
      "/lhome/matiada/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.3078, 'grad_norm': 89.18677520751953, 'learning_rate': 0.0002, 'epoch': 2.00555748523793}\n",
      "{'loss': 11.8662, 'grad_norm': 58.191749572753906, 'learning_rate': 0.0002, 'epoch': 2.0333449114275792}\n",
      "{'loss': 12.388, 'grad_norm': 58.572391510009766, 'learning_rate': 0.0002, 'epoch': 2.061132337617228}\n",
      "{'loss': 13.1126, 'grad_norm': 457.8995056152344, 'learning_rate': 0.0002, 'epoch': 2.0889197638068775}\n",
      "{'loss': 12.9864, 'grad_norm': 144.6287384033203, 'learning_rate': 0.0002, 'epoch': 2.1167071899965264}\n",
      "{'loss': 12.2096, 'grad_norm': 107.73517608642578, 'learning_rate': 0.0002, 'epoch': 2.1444946161861758}\n",
      "{'loss': 11.5676, 'grad_norm': 43.075313568115234, 'learning_rate': 0.0002, 'epoch': 2.172282042375825}\n",
      "{'loss': 11.088, 'grad_norm': 31.716068267822266, 'learning_rate': 0.0002, 'epoch': 2.200069468565474}\n",
      "{'loss': 12.1889, 'grad_norm': 29.80038070678711, 'learning_rate': 0.0002, 'epoch': 2.2278568947551234}\n",
      "{'loss': 11.2747, 'grad_norm': 85.05868530273438, 'learning_rate': 0.0002, 'epoch': 2.2556443209447723}\n",
      "{'loss': 11.6744, 'grad_norm': 126.60253143310547, 'learning_rate': 0.0002, 'epoch': 2.2834317471344217}\n",
      "{'loss': 12.1228, 'grad_norm': 90.97189331054688, 'learning_rate': 0.0002, 'epoch': 2.311219173324071}\n",
      "{'loss': 11.8425, 'grad_norm': 42.12588882446289, 'learning_rate': 0.0002, 'epoch': 2.33900659951372}\n",
      "{'loss': 11.2598, 'grad_norm': 76.74417877197266, 'learning_rate': 0.0002, 'epoch': 2.3667940257033693}\n",
      "{'loss': 11.0847, 'grad_norm': 182.29795837402344, 'learning_rate': 0.0002, 'epoch': 2.3945814518930186}\n",
      "{'loss': 11.2805, 'grad_norm': 62.97255325317383, 'learning_rate': 0.0002, 'epoch': 2.4223688780826675}\n",
      "{'loss': 10.8279, 'grad_norm': 51.10029602050781, 'learning_rate': 0.0002, 'epoch': 2.450156304272317}\n",
      "{'loss': 11.053, 'grad_norm': 46.70248031616211, 'learning_rate': 0.0002, 'epoch': 2.477943730461966}\n",
      "{'loss': 10.6261, 'grad_norm': 32.90544128417969, 'learning_rate': 0.0002, 'epoch': 2.505731156651615}\n",
      "{'loss': 12.1495, 'grad_norm': 72.97712707519531, 'learning_rate': 0.0002, 'epoch': 2.533518582841264}\n",
      "{'loss': 10.9313, 'grad_norm': 69.8824691772461, 'learning_rate': 0.0002, 'epoch': 2.5613060090309134}\n",
      "{'loss': 10.8415, 'grad_norm': 72.60249328613281, 'learning_rate': 0.0002, 'epoch': 2.589093435220563}\n",
      "{'loss': 11.6226, 'grad_norm': 30.65470314025879, 'learning_rate': 0.0002, 'epoch': 2.6168808614102117}\n",
      "{'loss': 11.7374, 'grad_norm': 41.95088577270508, 'learning_rate': 0.0002, 'epoch': 2.644668287599861}\n",
      "{'loss': 10.4194, 'grad_norm': 18.22012710571289, 'learning_rate': 0.0002, 'epoch': 2.6724557137895104}\n",
      "{'loss': 11.4471, 'grad_norm': 20.625598907470703, 'learning_rate': 0.0002, 'epoch': 2.7002431399791593}\n",
      "{'loss': 10.5687, 'grad_norm': 54.35467529296875, 'learning_rate': 0.0002, 'epoch': 2.7280305661688087}\n",
      "{'loss': 11.2205, 'grad_norm': 46.34745407104492, 'learning_rate': 0.0002, 'epoch': 2.755817992358458}\n",
      "{'loss': 11.5665, 'grad_norm': 38.17451477050781, 'learning_rate': 0.0002, 'epoch': 2.783605418548107}\n",
      "{'loss': 10.7551, 'grad_norm': 58.40611267089844, 'learning_rate': 0.0002, 'epoch': 2.8113928447377563}\n",
      "{'loss': 11.2462, 'grad_norm': 54.730037689208984, 'learning_rate': 0.0002, 'epoch': 2.839180270927405}\n",
      "{'loss': 11.17, 'grad_norm': 30.442665100097656, 'learning_rate': 0.0002, 'epoch': 2.8669676971170546}\n",
      "{'loss': 11.1889, 'grad_norm': 55.90180969238281, 'learning_rate': 0.0002, 'epoch': 2.8947551233067035}\n",
      "{'loss': 10.3829, 'grad_norm': 36.22096633911133, 'learning_rate': 0.0002, 'epoch': 2.922542549496353}\n",
      "{'loss': 10.7579, 'grad_norm': 43.04685974121094, 'learning_rate': 0.0002, 'epoch': 2.950329975686002}\n",
      "{'loss': 11.131, 'grad_norm': 847.0999145507812, 'learning_rate': 0.0002, 'epoch': 2.978117401875651}\n",
      "{'eval_loss': 1.470847249031067, 'eval_runtime': 170.2342, 'eval_samples_per_second': 22.604, 'eval_steps_per_second': 5.651, 'epoch': 2.997568600208406}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/matiada/venv/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:134: FutureWarning: The `ignore_index` attribute is deprecated and will be removed in v4.47.\n",
      "  warnings.warn(\n",
      "/lhome/matiada/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 11.9082, 'grad_norm': 30.381389617919922, 'learning_rate': 0.0002, 'epoch': 3.0083362278568946}\n",
      "{'loss': 11.5827, 'grad_norm': 80.5597152709961, 'learning_rate': 0.0002, 'epoch': 3.036123654046544}\n",
      "{'loss': 10.0318, 'grad_norm': 130.72198486328125, 'learning_rate': 0.0002, 'epoch': 3.0639110802361933}\n",
      "{'loss': 10.469, 'grad_norm': 33.25981903076172, 'learning_rate': 0.0002, 'epoch': 3.091698506425842}\n",
      "{'loss': 11.4779, 'grad_norm': 22.58572006225586, 'learning_rate': 0.0002, 'epoch': 3.1194859326154916}\n",
      "{'loss': 10.1526, 'grad_norm': 112.7008285522461, 'learning_rate': 0.0002, 'epoch': 3.1472733588051405}\n",
      "{'loss': 10.3681, 'grad_norm': 29.747241973876953, 'learning_rate': 0.0002, 'epoch': 3.17506078499479}\n",
      "{'loss': 10.4871, 'grad_norm': 85.02025604248047, 'learning_rate': 0.0002, 'epoch': 3.202848211184439}\n",
      "{'loss': 10.4419, 'grad_norm': 57.546329498291016, 'learning_rate': 0.0002, 'epoch': 3.230635637374088}\n",
      "{'loss': 10.8694, 'grad_norm': 24.745731353759766, 'learning_rate': 0.0002, 'epoch': 3.2584230635637375}\n",
      "{'loss': 10.3574, 'grad_norm': 29.94295883178711, 'learning_rate': 0.0002, 'epoch': 3.286210489753387}\n",
      "{'loss': 11.3884, 'grad_norm': 47.752986907958984, 'learning_rate': 0.0002, 'epoch': 3.3139979159430357}\n",
      "{'loss': 10.3884, 'grad_norm': 73.30873107910156, 'learning_rate': 0.0002, 'epoch': 3.341785342132685}\n",
      "{'loss': 10.6336, 'grad_norm': 29.413789749145508, 'learning_rate': 0.0002, 'epoch': 3.369572768322334}\n",
      "{'loss': 11.1361, 'grad_norm': 58.67774963378906, 'learning_rate': 0.0002, 'epoch': 3.3973601945119833}\n",
      "{'loss': 11.3371, 'grad_norm': 33.36803436279297, 'learning_rate': 0.0002, 'epoch': 3.4251476207016327}\n",
      "{'loss': 10.717, 'grad_norm': 62.47187423706055, 'learning_rate': 0.0002, 'epoch': 3.4529350468912816}\n",
      "{'loss': 9.7904, 'grad_norm': 32.99412536621094, 'learning_rate': 0.0002, 'epoch': 3.480722473080931}\n",
      "{'loss': 10.8034, 'grad_norm': 31.379594802856445, 'learning_rate': 0.0002, 'epoch': 3.50850989927058}\n",
      "{'loss': 10.1975, 'grad_norm': 41.9273796081543, 'learning_rate': 0.0002, 'epoch': 3.5362973254602292}\n",
      "{'loss': 10.2073, 'grad_norm': 72.92974090576172, 'learning_rate': 0.0002, 'epoch': 3.5640847516498786}\n",
      "{'loss': 11.1926, 'grad_norm': 526.7091674804688, 'learning_rate': 0.0002, 'epoch': 3.5918721778395275}\n",
      "{'loss': 10.8696, 'grad_norm': 130.1422119140625, 'learning_rate': 0.0002, 'epoch': 3.619659604029177}\n",
      "{'loss': 9.9991, 'grad_norm': 53.05218505859375, 'learning_rate': 0.0002, 'epoch': 3.647447030218826}\n",
      "{'loss': 9.6468, 'grad_norm': 44.24980545043945, 'learning_rate': 0.0002, 'epoch': 3.675234456408475}\n",
      "{'loss': 9.7388, 'grad_norm': 57.546783447265625, 'learning_rate': 0.0002, 'epoch': 3.7030218825981245}\n",
      "{'loss': 10.4149, 'grad_norm': 44.37609100341797, 'learning_rate': 0.0002, 'epoch': 3.7308093087877734}\n",
      "{'loss': 10.9092, 'grad_norm': 42.92007827758789, 'learning_rate': 0.0002, 'epoch': 3.7585967349774227}\n",
      "{'loss': 10.0871, 'grad_norm': 49.30559539794922, 'learning_rate': 0.0002, 'epoch': 3.7863841611670717}\n",
      "{'loss': 9.8995, 'grad_norm': 54.97489929199219, 'learning_rate': 0.0002, 'epoch': 3.814171587356721}\n",
      "{'loss': 9.8461, 'grad_norm': 35.8375129699707, 'learning_rate': 0.0002, 'epoch': 3.8419590135463704}\n",
      "{'loss': 10.4437, 'grad_norm': 106.050048828125, 'learning_rate': 0.0002, 'epoch': 3.8697464397360193}\n",
      "{'loss': 10.479, 'grad_norm': 50.08771514892578, 'learning_rate': 0.0002, 'epoch': 3.8975338659256686}\n",
      "{'loss': 9.9214, 'grad_norm': 19.557132720947266, 'learning_rate': 0.0002, 'epoch': 3.925321292115318}\n",
      "{'loss': 9.6319, 'grad_norm': 63.9843635559082, 'learning_rate': 0.0002, 'epoch': 3.953108718304967}\n",
      "{'loss': 10.5283, 'grad_norm': 59.698890686035156, 'learning_rate': 0.0002, 'epoch': 3.9808961444946163}\n",
      "{'eval_loss': 1.2225674390792847, 'eval_runtime': 169.3174, 'eval_samples_per_second': 22.727, 'eval_steps_per_second': 5.682, 'epoch': 3.997568600208406}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/matiada/venv/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:134: FutureWarning: The `ignore_index` attribute is deprecated and will be removed in v4.47.\n",
      "  warnings.warn(\n",
      "/lhome/matiada/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.1289, 'grad_norm': 65.82814025878906, 'learning_rate': 0.0002, 'epoch': 4.01111497047586}\n",
      "{'loss': 9.7837, 'grad_norm': 44.156494140625, 'learning_rate': 0.0002, 'epoch': 4.038902396665509}\n",
      "{'loss': 9.9447, 'grad_norm': 83.00977325439453, 'learning_rate': 0.0002, 'epoch': 4.0666898228551585}\n",
      "{'loss': 9.1739, 'grad_norm': 43.1068229675293, 'learning_rate': 0.0002, 'epoch': 4.094477249044807}\n",
      "{'loss': 9.3519, 'grad_norm': 83.94661712646484, 'learning_rate': 0.0002, 'epoch': 4.122264675234456}\n",
      "{'loss': 9.1861, 'grad_norm': 34.68849182128906, 'learning_rate': 0.0002, 'epoch': 4.150052101424105}\n",
      "{'loss': 9.6047, 'grad_norm': 59.67850112915039, 'learning_rate': 0.0002, 'epoch': 4.177839527613755}\n",
      "{'loss': 9.7801, 'grad_norm': 74.53050231933594, 'learning_rate': 0.0002, 'epoch': 4.205626953803404}\n",
      "{'loss': 9.8157, 'grad_norm': 67.88227844238281, 'learning_rate': 0.0002, 'epoch': 4.233414379993053}\n",
      "{'loss': 10.105, 'grad_norm': 685.7171630859375, 'learning_rate': 0.0002, 'epoch': 4.261201806182703}\n",
      "{'loss': 11.1331, 'grad_norm': 65.78089904785156, 'learning_rate': 0.0002, 'epoch': 4.2889892323723515}\n",
      "{'loss': 9.3051, 'grad_norm': 20.556884765625, 'learning_rate': 0.0002, 'epoch': 4.316776658562}\n",
      "{'loss': 9.949, 'grad_norm': 101.82145690917969, 'learning_rate': 0.0002, 'epoch': 4.34456408475165}\n",
      "{'loss': 9.5808, 'grad_norm': 76.69326782226562, 'learning_rate': 0.0002, 'epoch': 4.372351510941299}\n",
      "{'loss': 9.017, 'grad_norm': 18.521326065063477, 'learning_rate': 0.0002, 'epoch': 4.400138937130948}\n",
      "{'loss': 8.7169, 'grad_norm': 150.36521911621094, 'learning_rate': 0.0002, 'epoch': 4.427926363320598}\n",
      "{'loss': 9.6858, 'grad_norm': 65.30017852783203, 'learning_rate': 0.0002, 'epoch': 4.455713789510247}\n",
      "{'loss': 10.229, 'grad_norm': 16.12132453918457, 'learning_rate': 0.0002, 'epoch': 4.483501215699896}\n",
      "{'loss': 10.226, 'grad_norm': 113.70000457763672, 'learning_rate': 0.0002, 'epoch': 4.511288641889545}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2529\u001b[0m )\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2537\u001b[0m ):\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/transformers/trainer.py:3713\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3711\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[0;32m-> 3713\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/accelerate/accelerator.py:2248\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2248\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "767add6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
