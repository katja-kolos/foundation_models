import logging
import numpy as np
import pandas as pd
import torch

from datasets import load_dataset
from datetime import datetime
from PIL import Image
from torch.utils.data import DataLoader
from tqdm import tqdm

from qwen_vl_utils import process_vision_info #this is some basic if-else image processing, can be reused as is for paligemma runs
from prefix_tuning import PrefixTuningModel, PrefixDataset, prefix_collate
from dataset_utils import *


"""
Script to prefix-train a generative MLLM
Was initially written for qwen, current adaptation is for paligemma
The training data is the multimodal ScienceQA dataset. 
The targets are free-text solutions, which are compared to solutions generated by the model. The answer field (int: [1:4]) is not used in this implementation.
Assumed model architecture: autoregressive textual model + visual encoder
Script only runs on cuda and does not support CPU-only runs
"""

# Empty cache just in case
torch.cuda.empty_cache()

# Logging
# Generate timestamped filename
start_time = datetime.now().strftime("%Y%m%d_%H%M%S")
log_filename = f"prefix-tuning_{start_time}.log"
# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(log_filename),  # Log to file
        logging.StreamHandler()            # Also log to console (optional)
    ]
)

# CONSTANTS
NUM_EPOCHS_FT = 5
BATCH_SIZE = 4
logging.info(f'Set constants: NUM_EPOCHS_FT={NUM_EPOCHS_FT}, BATCH_SIZE={BATCH_SIZE}')

# Main script
device = 'cuda' # torch.cuda.get_device_name(0)
logging.info(torch.cuda.get_device_name(0))
logging.info('Memory Usage:')
logging.info(f'Allocated: {round(torch.cuda.memory_allocated(0)/1024**3,1)} GB')
logging.info(f'Cached: {round(torch.cuda.memory_reserved(0)/1024**3,1)} GB')

### train data
# data with label and image data
df_train_label = pd.DataFrame(load_dataset('derek-thomas/ScienceQA', split='train'))
logging.info(f'Loaded train dataset with {len(df_train_label)} rows')

df_train_label = df_train_label[df_train_label['solution'] != ''].reset_index()
df_train_label['image'] = df_train_label.apply(lambda row: row['image'] if row['image'] else Image.new("RGB", (224, 224), (0, 0, 0)), axis=1)
df_train_label['input'] = df_train_label.apply(lambda row: build_prompt(row)[0], axis=1)
df_train_label['message'] = df_train_label.apply(lambda row: build_message(row), axis=1)

### val data
df_val = pd.DataFrame(load_dataset('derek-thomas/ScienceQA', split='validation'))
# filter validation data; #TODO: would it be wiser to validate on exactly the same subset used for benchmarking? or to have as much data as possible?
df_val = df_val[df_val['solution'] != ''].reset_index()
df_val['image'] = df_val.apply(lambda row: row['image'] if row['image'] else Image.new("RGB", (224, 224), (0, 0, 0)), axis=1)
df_val['input'] = df_val.apply(lambda row: build_prompt(row)[0], axis=1)
df_val['message'] = df_val.apply(lambda row: build_message(row), axis=1)
logging.info(f'Loaded validation with {len(df_val)} rows')

def preprocess_input_qwen(tokenizer, processor, prompts, texts, images, y, device):
    messages = [processor.apply_chat_template(
                text, tokenize=False, add_generation_prompt=False
    ) for text in texts]
    image_inputs, video_inputs = process_vision_info(texts)
    inputs = processor(
        text=messages,
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
    )
    max_length = inputs["input_ids"].size(1) + 10 # +10 for later prefix
    labels = tokenizer(y, padding="max_length", truncation=True, max_length=max_length, return_tensors="pt")["input_ids"]
    return inputs.to(device, dtype=torch.bfloat16), labels.to(device)

def train(model, tokenizer, processor, optimizer, dataloader_train, dataloader_val, preprocess_func):
    train_errors = []
    val_errors = []
    model.train()
    logging.info('Set model into train mode')
    for epoch in tqdm(range(NUM_EPOCHS_FT)):
        error = 0
        num_samples = 0
        for prompts, texts, images, y in dataloader_train:
            inputs, labels = preprocess_func(tokenizer, processor, prompts, texts, images, y, device)
            #logging.info("inputs")
            #logging.info(inputs)
            #logging.info("labels")
            #logging.info(labels)

            optimizer.zero_grad()
            #logging.info("forward pass")
            outputs = model(inputs, labels=labels)
            # detailed look into
            output_ids = outputs.logits.argmax(-1)
            output_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)
            #logging.info(output_text)

            loss = outputs.loss
            #logging.info(f"loss: {loss}")
            loss.backward()
            optimizer.step()
            error += loss.item() * len(texts)
            num_samples += len(texts)
            del labels, inputs
            gc.collect()
            torch.cuda.empty_cache()
            #logging.info("backward pass done")
        error /= num_samples
        logging.info(f'Error after epoch {epoch}: {error}')
        train_errors.append((epoch, error))
        if epoch % 5:
            val_error = 0
            num_samples = 0
            for prompts, texts, images, y in dataloader_val:
                inputs, labels = preprocess_func(tokenizer, processor, prompts, texts, images, y, device)
                outputs = model(
                    inputs=inputs,
                    labels=labels,
                )
                loss = outputs.loss
                val_error += loss.item() * len(texts)
                num_samples += len(texts)
                del labels, inputs
                gc.collect()
                torch.cuda.empty_cache()
            val_error /= num_samples
            logging.info(f'Validation error after epoch {epoch}: {val_error}')
            val_errors.append((epoch, val_error))
    return train_errors, val_error

# DataLoader for train data
dataset_label_train = PrefixDataset(df_train_label)
dataloader_label_train=DataLoader(dataset_label_train, collate_fn=prefix_collate, batch_size=BATCH_SIZE, shuffle=True)
logging.info('DataLoader for train ready')
# DataLoader for val data
dataset_label_val = PrefixDataset(df_val)
dataloader_label_val=DataLoader(dataset_label_val, collate_fn=prefix_collate, batch_size=BATCH_SIZE, shuffle=True)
logging.info('DataLoader for validation ready')

from transformers import AutoModelForImageTextToText, AutoTokenizer, AutoProcessor, Qwen2VLForConditionalGeneration
import gc

model_name = "Qwen/Qwen2-VL-2B-Instruct"
logging.info(f'Model: {model_name}')

model = AutoModelForImageTextToText.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16 #"auto"
)
logging.info('Loaded model')
tokenizer = AutoTokenizer.from_pretrained(model_name)
logging.info('Loaded tokenizer')
processor = AutoProcessor.from_pretrained(model_name)
logging.info('Loaded processor')

model_prefix = PrefixTuningModel(model, tokenizer).to(device)
logging.info('Ready: PrefixTuningModel')
optimizer = torch.optim.AdamW(model_prefix.prefix_tuning.parameters(), lr=5e-5)
logging.info('Ready: optimizer')

logging.info('Starting training')
train_errors_ft_qwen, val_errors_ft_qwen = train(model_prefix, tokenizer, processor, optimizer, dataloader_label_train, dataloader_label_val, preprocess_input_qwen)

# Save assets
logging.info('Saving assets')
saving_path = f"{model_name.replace('/', '_').lower()}_pref_{NUM_EPOCHS_FT}_{BATCH_SIZE}"
torch.save(model.state_dict(), saving_path)
logging.info(f'Saved model to path: {saving_path}')
with open(f'{saving_path}_train_error', 'w') as f:
    f.write(train_errors_ft_qwen)
    logging.info('Saved train_errors')
with open(f'{saving_path}_val_error', 'w') as f:
    f.write(val_errors_ft_qwen)
    logging.info('Saved validation_errors')

logging.info('Done')
