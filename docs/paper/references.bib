@Article{lu2022learn,
  title     =   {Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author    =   {Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal   =   {Advances in Neural Information Processing Systems},
  volume    =   {35},
  pages     =   {2507--2521},
  year      =   {2022}
}

@Article{deepseek-r1,
  title     =   {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}
}

@inproceedings{li2021prefix,
  title     =   {Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author    =   {Li, Xiang Lisa and Liang, Percy},
  booktitle =   {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages     =   {4582--4597},
  year      =   {2021}
}

%note: it looks like it was not published; there were subsequent reprints at e.g. university websites, but no "official" publication
@Article{hu2021lora,
  title     =   {Lora: Low-rank adaptation of large language models},
  author    =   {Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal   =   {arXiv preprint arXiv:2106.09685},
  year      =   {2021}
}

@inproceedings{lin2004rouge,
  title     =   {Rouge: A package for automatic evaluation of summaries},
  author    =   {Lin, Chin-Yew},
  booktitle =   {Text summarization branches out},
  pages     =   {74--81},
  year      =   {2004}
}

%note: references below are a copy from the paper version in our github
%% knowledge distillation
@article{shridhar2022distilling,
  title={Distilling reasoning capabilities into smaller language models},
  author={Shridhar, Kumar and Stolfo, Alessandro and Sachan, Mrinmaya},
  journal={arXiv preprint arXiv:2212.00193},
  year={2022}
}
@article{magister2022teaching,
  title={Teaching small language models to reason},
  author={Magister, Lucie Charlotte and Mallinson, Jonathan and Adamek, Jakub and Malmi, Eric and Severyn, Aliaksei},
  journal={arXiv preprint arXiv:2212.08410},
  year={2022}
}
@inproceedings{li2024turning,
  title={Turning dust into gold: Distilling complex reasoning capabilities from llms by leveraging negative data},
  author={Li, Yiwei and Yuan, Peiwen and Feng, Shaoxiong and Pan, Boyuan and Sun, Bin and Wang, Xinglin and Wang, Heda and Li, Kan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={18591--18599},
  year={2024}
}
@article{gou2021knowledge,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}
@article{yu2023dataset,
  title={Dataset distillation: A comprehensive review},
  author={Yu, Ruonan and Liu, Songhua and Wang, Xinchao},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}
%%% feature-based KD
@article{sepahvand2022teacher,
  title={Teacher--student knowledge distillation based on decomposed deep feature representation for intelligent mobile applications},
  author={Sepahvand, Majid and Abdali-Mohammadi, Fardin and Taherkordi, Amir},
  journal={Expert Systems with Applications},
  volume={202},
  pages={117474},
  year={2022},
  publisher={Elsevier}
}
%% prompt design
@article{schulhoff2024prompt,
  title={The Prompt Report: A Systematic Survey of Prompting Techniques},
  author={Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and others},
  journal={arXiv preprint arXiv:2406.06608},
  year={2024}
}
@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}
@article{chang2024efficient,
  title={Efficient Prompting Methods for Large Language Models: A Survey},
  author={Chang, Kaiyan and Xu, Songcheng and Wang, Chenglong and Luo, Yingfeng and Xiao, Tong and Zhu, Jingbo},
  journal={arXiv preprint arXiv:2404.01077},
  year={2024}
}
@article{zhou2022large,
  title={Large language models are human-level prompt engineers},
  author={Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
  journal={arXiv preprint arXiv:2211.01910},
  year={2022}
}
@article{ge2023context,
  title={In-context autoencoder for context compression in a large language model},
  author={Ge, Tao and Hu, Jing and Wang, Lei and Wang, Xun and Chen, Si-Qing and Wei, Furu},
  journal={arXiv preprint arXiv:2307.06945},
  year={2023}
}
@article{weston2023system,
  title={System 2 Attention (is something you might need too)},
  author={Weston, Jason and Sukhbaatar, Sainbayar},
  journal={arXiv preprint arXiv:2311.11829},
  year={2023}
}
%% agentic architectures
@article{lin2024swiftsage,
  title={Swiftsage: A generative agent with fast and slow thinking for complex interactive tasks},
  author={Lin, Bill Yuchen and Fu, Yicheng and Yang, Karina and Brahman, Faeze and Huang, Shiyu and Bhagavatula, Chandra and Ammanabrolu, Prithviraj and Choi, Yejin and Ren, Xiang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{ghafarollahi2024sciagents,
  title={SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning},
  author={Ghafarollahi, Alireza and Buehler, Markus J},
  journal={arXiv preprint arXiv:2409.05556},
  year={2024}
}
@article{karpas2022mrkl,
  title={MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning},
  author={Karpas, Ehud and Abend, Omri and Belinkov, Yonatan and Lenz, Barak and Lieber, Opher and Ratner, Nir and Shoham, Yoav and Bata, Hofit and Levine, Yoav and Leyton-Brown, Kevin and others},
  journal={arXiv preprint arXiv:2205.00445},
  year={2022}
}
@article{lester2021prompt,
    title={The Power of Scale for Parameter-Efficient Prompt Tuning},
    author={Brian Lester, Rami Al-Rfou, Noah Constant},
    journal={arXiv preprint arXiv:2104.08691},
    year={2021}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}


%metrics
}
@article{ghafarollahi2024sciagents,
  title={SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning},
  author={Ghafarollahi, Alireza and Buehler, Markus J},
  journal={arXiv preprint arXiv:2409.05556},
  year={2024}
}


@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}
@article{beltagy2019scibert,
  title={SciBERT: A pretrained language model for scientific text},
  author={Beltagy, Iz and Lo, Kyle and Cohan, Arman},
  journal={arXiv preprint arXiv:1903.10676},
  year={2019}
}
@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@misc{OpenAI2024o1,
  author    = {OpenAI},
  title     = {OpenAI o1 System Card},
  year      = {2024},
  url       = {https://openai.com/index/openai-o1-system-card/}
}

@article{mao2025survey,
  title={A survey on lora of large language models},
  author={Mao, Yuren and Ge, Yuhang and Fan, Yijiang and Xu, Wenyi and Mi, Yu and Hu, Zhonghao and Gao, Yunjun},
  journal={Frontiers of Computer Science},
  volume={19},
  number={7},
  pages={197605},
  year={2025},
  publisher={Springer}
}