%%%%%%%%%
% Generic article template using additional packages for table formatting
% New commands are defined for project participants: \katja, \flo, \dasha - 
% to draw attention to important remarks directly in the text
%%%%%%%%%

\documentclass{article}

\usepackage{graphicx}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{adjustbox}

\newcommand{\katja}[1]{\textbf{\textcolor{teal}{(Katja) #1}}}
\newcommand{\dasha}[1]{\textbf{\textcolor{brown}{(Dasha) #1}}}
\newcommand{\flo}[1]{\textbf{\textcolor{red}{(Flo) #1}}}


\begin{document}

\title{Scientific Reasoning with LLMs}

\author{Group ??: Florian \and Ekaterina Kolos \and Daria }

\maketitle             


\section{Introduction}

Scientific machine reasoning is ... 

For our project, we intend to ...

Expected implementation details ...

\section{Background and Related Work}
% Large Language Models

Knowledge distillation allows to obtain smaller models capable of successfully following the behavior of larger "teacher" models. This is particularly useful for privacy reasons (running AI applications on mobile devices) and for cases where access to very large models in the cloud is not guaranteed (e.g. in cars). Some approaches to knowledge distillation include: \begin{itemize}
    \item distillation of outputs, incl. CoT knowledge distillation, e.g. 
    \begin{itemize}
    \item self-consistency decoding: "The teacher model generates multiple CoT responses, and the student learns from the aggregate (self-consistent) reasoning paths, which can help the student model avoid common mistakes and output more consistent answers." 
    \item intermediate answers: "Generate CoT reasoning outputs from a large teacher model on reasoning. The student model will be fine-tuned using these CoT responses to produce intermediate reasoning steps."
    \end{itemize}
    \item distillation of features on intermediate layers 
    %\item CoT knowledge distillation \cite{shridhar2022distilling} 
    \item teacher model to produce training data for student model: "Use the teacher model to generate correct reasoning paths and analyze where the student model diverges. Distill additional targeted knowledge by emphasizing examples where the student struggles, focusing on error types like logical consistency or arithmetic errors."
    \item architecture-based distillation
\end{itemize}
Our goal is to test whether any of these techniques can be successfully used to obtain a model with scientific reasoning capabilities. 

Agent-based architectures \cite{lin2024swiftsage} \cite{ghafarollahi2024sciagents}

Prompting techniques \cite{schulhoff2024prompt}

Scientific reasoning and the dataset \cite{lu2022learn}

\section{Methodology}
We postulate the following research questions: 
RQ1: Can smaller student LLMs be still effective at few-shot prompting for scientific reasoning?
RQ2: How does their performance compare with that of a teacher model?
RQ3: 
\paragraph{RQ1} 
We plan to 

\paragraph{RQ2}
We plan to

\paragraph{RQ3}
We plan to

\paragraph{Metrics}

\section{Approximate Timeline}
Maybe just a paragraph here


\katja{Have reverted the doc to simple "article"}

\bibliography{mybibliography}
\bibliographystyle{plain}

\end{document}
