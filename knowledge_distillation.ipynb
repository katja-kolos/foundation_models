{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ktdrhWnZ87XJ",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6TP2Hzr87XM",
    "outputId": "2c09cfa8-ab7b-402a-de07-099e0163bc85"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import ast\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import helpers\n",
    "import soft_prompting\n",
    "import importlib\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(soft_prompting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvM8QDGl87XP"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "\n",
    "# CONSTANTS\n",
    "NUM_EPOCHS_FT = 100\n",
    "NUM_EPOCHS_KD = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "pNEtAiGe87XP",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Get Data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjuLrTbq87XQ"
   },
   "outputs": [],
   "source": [
    "### train data\n",
    "# data with label and image data\n",
    "df_train_label = load_dataset('derek-thomas/ScienceQA', split='train')\n",
    "\n",
    "# df_train_label = df_train_label[df_train_label['solution'] != ''].reset_index()\n",
    "# df_train_label['input'] = df_train_label.apply(lambda row: helpers.build_prompt(row)[0], axis=1)\n",
    "# df_train_label[['index', 'input', 'answer', 'explanation', 'image']] = df_train_label[['index', 'input', 'answer', 'solution', 'image']]\n",
    "\n",
    "# # data from Gemini for KD\n",
    "# df_train_gemini = pd.read_csv('gemini_1_5_flash_output_train.csv', sep=\"\\t\")[['index', 'input', 'answer', 'explanation']]\n",
    "# df_train_gemini = pd.merge(df_train_gemini, df_train_label[['index', 'image']], on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izTEvl6i87XR"
   },
   "outputs": [],
   "source": [
    "### val data\n",
    "df_val = pd.DataFrame(load_dataset('derek-thomas/ScienceQA', split='validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# default: Load the model on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default processer\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_dataset(df, tokenizer, input_column=\"input\"):\n",
    "\n",
    "    tokenized_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        sample = {}\n",
    "        sample[\"input_ids\"] = tokenizer.encode(row[input_column], return_tensors=\"pt\").squeeze(0)\n",
    "        \n",
    "        tokenized_data.append(sample)\n",
    "    return tokenized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default range for the number of visual tokens per image in the model is 4-16384. You can set min_pixels and max_pixels according to your needs, such as a token count range of 256-1280, to balance speed and memory usage.\n",
    "# min_pixels = 256*28*28\n",
    "# max_pixels = 1280*28*28\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": df_train_label[11]['image'],\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": df_train_label[11]['question'] + \" \" + ' '.join(df_train_label[11]['choices'])},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# Inference: Generation of the output\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_label[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_label[11]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_gemini.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Datensatz tokenisieren\n",
    "tokenized_data = tokenize_dataset(df_train_gemini, tokenizer, input_column=\"input\", label_column=\"answer\")\n",
    "\n",
    "# Dataset erstellen\n",
    "dataset = SoftPromptingDataset(tokenized_data)\n",
    "\n",
    "# Zugriff auf ein Beispiel\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "NStdSFIf87XS",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Functions for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBOk6eSR87XT"
   },
   "outputs": [],
   "source": [
    "def train(dataloader_train, dataloader_val):\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "    for epoch in tqdm(range(NUM_EPOCHS_FT)):\n",
    "        error = 0\n",
    "        num_samples = 0\n",
    "        for input, answer, explanation, image in dataloader_train:\n",
    "            pass\n",
    "            # forward\n",
    "            # loss = ...\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            # error += loss.item() * X.size(0)\n",
    "            # num_samples += X.size(0)\n",
    "        error /= num_samples\n",
    "        print(f'Error after epoch {epoch}: {error}')\n",
    "        train_errors.append((epoch, error))\n",
    "        if epoch % 10:\n",
    "            val_error = 0\n",
    "            num_samples\n",
    "            for input, answer, explanation, image in dataloader_val:\n",
    "                pass\n",
    "                # forward\n",
    "                # loss = ...\n",
    "                # val_error += loss.item() * X.size(0)\n",
    "                # num_samples += X.size(0)\n",
    "            val_error /= num_samples\n",
    "            print(f'Validation error after epoch {epoch}: {val_error}')\n",
    "            val_errors.append((epoch, val_error))\n",
    "    return train_errors_ft, val_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKhEnvHx87XU"
   },
   "outputs": [],
   "source": [
    "def visualize_error(train_errors, val_errors):\n",
    "    plt.plot(zip(*train_errors), label=\"Train Error\", marker=\"o\", linestyle=\"-\")\n",
    "    plt.plot(zip(*val_errors), label=\"Train Error\", marker=\"o\", linestyle=\"-\")\n",
    "    plt.title(\"Train and Validation Error over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "eoPYPMBq87XU",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Soft prompting using labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tcw_Fj0R87XV"
   },
   "outputs": [],
   "source": [
    "# model = None # ToDo\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "model_fine_tuned = soft_prompting.MultimodalSoftPrompting.from_pretrained(model)\n",
    "# DataLoader for train data\n",
    "dataset_label_train = SoftPromptingDataset(df_train_label, model_fine_tuned)\n",
    "dataloader_label_train=DataLoader(dataset_label_train, batch_size=32, shuffle=True)\n",
    "# DataLoader for val data\n",
    "dataset_label_val = SoftPromptingDataset(df_val, model_fine_tuned)\n",
    "dataloader_label_val=DataLoader(dataset_label_val, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBY-hEz687XV"
   },
   "outputs": [],
   "source": [
    "train_errors_ft, val_errors_ft = train(dataloader_label_train, dataloader_label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weNRYFe787XX"
   },
   "outputs": [],
   "source": [
    "visualize_error(train_errors_ft, val_errors_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "qw5SW6bP87XY",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZV4PV0m087XY"
   },
   "outputs": [],
   "source": [
    "model = None # ToDo\n",
    "model_knowledge_distillation = soft_prompting.MultimodalSoftPrompting.from_pretrained(model)\n",
    "# DataLoader for train data\n",
    "dataset_gemini_train = SoftPromptingDataset(df_train_gemini, model_fine_tuned)\n",
    "dataloader_gemini_train=DataLoader(dataset_gemini_train, batch_size=32, shuffle=True)\n",
    "# DataLoader for val data\n",
    "dataset_gemini_val = SoftPromptingDataset(df_val, model_fine_tuned)\n",
    "dataloader_gemini_val=DataLoader(dataset_gemini_val, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZP04R7VX87XZ"
   },
   "outputs": [],
   "source": [
    "train_errors_kd, val_errors_kd = train(dataset_gemini_train, dataloader_gemini_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJn7pB2b87XZ"
   },
   "outputs": [],
   "source": [
    "visualize_error(train_errors_kd, val_errors_kd)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
