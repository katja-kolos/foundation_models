{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports & Setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T16:28:41.723228Z",
     "start_time": "2025-01-06T16:28:29.919567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from helpers import build_prompt, build_message, login_to_hf\n",
    "from prefix_tuning import PrefixTuningModelPastKeyValues, PrefixDataset, prefix_collate\n",
    "import prefix_tuning\n",
    "import helpers\n",
    "import importlib\n",
    "from PIL import Image\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from transformers import AutoModelForImageTextToText, AutoTokenizer, AutoProcessor, PaliGemmaProcessor, PaliGemmaForConditionalGeneration\n",
    "import gc\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(prefix_tuning)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'prefix_tuning' from '/Users/floriandreyer/Library/Mobile Documents/com~apple~CloudDocs/Python Projekte/foundation_models/prefix_tuning.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "login_to_hf()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device(\"mps\")\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "\n",
    "#device = torch.device('cuda:0,1' if torch.cuda.is_available() else 'cpu')\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "# CONSTANTS\n",
    "NUM_EPOCHS_FT = 100\n",
    "NUM_EPOCHS_KD = 100\n",
    "BATCH_SIZE = 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "device",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!nvidia-smi",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get Data and preprocess it"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### train data\n",
    "# data with label and image data\n",
    "df_train_label = pd.DataFrame(load_dataset('derek-thomas/ScienceQA', split='train'))\n",
    "\n",
    "df_train_label = df_train_label[df_train_label['solution'] != ''].reset_index()\n",
    "df_train_label['image'] = df_train_label.apply(lambda row: row['image'] if row['image'] else Image.new(\"RGB\", (224, 224), (0, 0, 0)), axis=1)\n",
    "df_train_label['input'] = df_train_label.apply(lambda row: build_prompt(row), axis=1)\n",
    "df_train_label['message'] = df_train_label.apply(lambda row: build_message(row), axis=1)\n",
    "\n",
    "# # data from Gemini for KD\n",
    "df_train_gemini = pd.read_csv('gemini_1_5_flash_output_train.csv', sep=\"\\t\")[['index', 'input', 'answer', 'explanation']]\n",
    "df_train_gemini = pd.merge(df_train_gemini, df_train_label[['index', 'image', 'solution']], on='index')\n",
    "df_train_gemini['message'] = df_train_gemini.apply(lambda row: build_message(row), axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### val data\n",
    "df_val = pd.DataFrame(load_dataset('derek-thomas/ScienceQA', split='validation'))\n",
    "\n",
    "df_val = df_val[df_val['solution'] != ''].reset_index()\n",
    "df_val['image'] = df_val.apply(lambda row: row['image'] if row['image'] else Image.new(\"RGB\", (224, 224), (0, 0, 0)), axis=1)\n",
    "df_val['input'] = df_val.apply(lambda row: build_prompt(row), axis=1)\n",
    "df_val['message'] = df_val.apply(lambda row: build_message(row), axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions for model training"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_input_qwen(tokenizer, processor, prompts, texts, images, y, device):\n",
    "    messages = [processor.apply_chat_template(\n",
    "                text, tokenize=False, add_generation_prompt=False\n",
    "    ) for text in texts]\n",
    "    image_inputs, video_inputs = process_vision_info(texts)\n",
    "    inputs = processor(\n",
    "        text=messages,\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    max_length = inputs[\"input_ids\"].size(1)\n",
    "    labels = tokenizer(y, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    return inputs.to(device, dtype=torch.bfloat16), labels.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_input_paligemma(tokenizer, processor, prompts, texts, images, y, device):\n",
    "    images = [image.resize((224, 224)) for image in images]\n",
    "    inputs = processor(\n",
    "        text=prompts,\n",
    "        images=images,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\"\n",
    "    )\n",
    "    max_length = inputs[\"input_ids\"].size(1)\n",
    "    labels = tokenizer(y, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    return inputs.to(device, dtype=torch.bfloat16), labels.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train(model, tokenizer, processor, optimizer, dataloader_train, dataloader_val, preprocess_func):\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(NUM_EPOCHS_FT)):\n",
    "        error = 0\n",
    "        num_samples = 0\n",
    "        for prompts, texts, images, y in dataloader_train:\n",
    "            inputs, labels = preprocess_func(tokenizer, processor, prompts, texts, images, y, device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(\n",
    "                    inputs=inputs,\n",
    "                    labels=labels,\n",
    "                )\n",
    "            #output_ids = outputs.logits.argmax(-1)\n",
    "            #output_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            error += loss.item() * len(texts)\n",
    "            num_samples += len(texts)\n",
    "            del labels, inputs\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        error /= num_samples\n",
    "        print(f'Error after epoch {epoch}: {error}')\n",
    "        train_errors.append((epoch, error))\n",
    "        if epoch % 10:\n",
    "            val_error = 0\n",
    "            num_samples = 0\n",
    "            for prompts, texts, images, y in dataloader_val:\n",
    "                inputs, labels = preprocess_func(tokenizer, processor, prompts, texts, images, y, device)\n",
    "                outputs = model(\n",
    "                    inputs=inputs,\n",
    "                    labels=labels,\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "                val_error += loss.item() * len(texts)\n",
    "                num_samples += len(texts)\n",
    "                del labels, inputs\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            val_error /= num_samples\n",
    "            print(f'Validation error after epoch {epoch}: {val_error}')\n",
    "            val_errors.append((epoch, val_error))\n",
    "    return train_errors, val_error"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualize_error(train_errors, val_errors):\n",
    "    plt.plot(zip(*train_errors), label=\"Train Error\", marker=\"o\", linestyle=\"-\")\n",
    "    plt.plot(zip(*val_errors), label=\"Train Error\", marker=\"o\", linestyle=\"-\")\n",
    "    plt.title(\"Train and Validation Error over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PrefixTuning using labels"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DataLoader for train data\n",
    "dataset_label_train = PrefixDataset(df_train_label)\n",
    "dataloader_label_train=DataLoader(dataset_label_train, collate_fn=prefix_collate, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# DataLoader for val data\n",
    "dataset_label_val = PrefixDataset(df_val)\n",
    "dataloader_label_val=DataLoader(dataset_label_val, collate_fn=prefix_collate, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Qwen"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "match_n_layer = model.config.num_hidden_layers\n",
    "match_n_head = model.config.num_key_value_heads\n",
    "n_embd = model.config.hidden_size // 6\n",
    "model_prefix = PrefixTuningModelPastKeyValues(model, match_n_layer, match_n_head, n_embd, device).to(device)\n",
    "optimizer = torch.optim.AdamW(model_prefix.prefix_tuning.parameters(), lr=5e-5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_errors_ft_qwen, val_errors_ft_qwen = train(model_prefix, tokenizer, processor, optimizer, dataloader_label_train, dataloader_label_val, preprocess_input_qwen)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_error(train_errors_ft_qwen, val_errors_ft_qwen)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Paligemma"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_id = \"google/paligemma2-3b-pt-224\"\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map={\"\": \"cpu\"})\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)\n",
    "\n",
    "match_n_layer = model.config.num_hidden_layers\n",
    "match_n_head = model.config.text_config.num_key_value_heads\n",
    "n_embd = model.config.hidden_size // 2\n",
    "model_prefix = PrefixTuningModelPastKeyValues(model, match_n_layer, match_n_head, n_embd, device).to(device)\n",
    "optimizer = torch.optim.AdamW(model_prefix.prefix_tuning.parameters(), lr=5e-5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "train_errors_ft_paligemma, val_errors_ft_paligemma = train(model_prefix, processor.tokenizer, processor, optimizer, dataloader_label_train, dataloader_label_val, preprocess_input_paligemma)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_error(train_errors_ft_paligemma, val_errors_ft_paligemma)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Knowledge Distillation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DataLoader for train data\n",
    "dataset_gemini_train = PrefixDataset(df_train_gemini)\n",
    "dataloader_gemini_train=DataLoader(dataset_gemini_train, collate_fn=prefix_collate, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# DataLoader for val data\n",
    "dataset_label_val = PrefixDataset(df_val)\n",
    "dataloader_label_val=DataLoader(dataset_label_val, collate_fn=prefix_collate, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Qwen"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "match_n_layer = model.config.num_hidden_layers\n",
    "match_n_head = model.config.num_key_value_heads\n",
    "n_embd = model.config.hidden_size // 6\n",
    "model_prefix = PrefixTuningModelPastKeyValues(model, match_n_layer, match_n_head, n_embd, device).to(device)\n",
    "optimizer = torch.optim.AdamW(model_prefix.prefix_tuning.parameters(), lr=5e-5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_errors_kd, val_errors_kd = train(dataset_gemini_train, dataloader_gemini_train)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_error(train_errors_kd, val_errors_kd)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Paligemma"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_id = \"google/paligemma2-3b-pt-224\"\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)\n",
    "\n",
    "match_n_layer = model.config.num_hidden_layers\n",
    "match_n_head = model.config.text_config.num_key_value_heads\n",
    "n_embd = model.config.hidden_size // 2\n",
    "model_prefix = PrefixTuningModelPastKeyValues(model, match_n_layer, match_n_head, n_embd, device).to(device)\n",
    "optimizer = torch.optim.AdamW(model_prefix.prefix_tuning.parameters(), lr=5e-5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_errors_kd_paligemma, val_errors_kd_paligemma = train(model_prefix, processor.tokenizer, processor, optimizer, dataloader_gemini_train, dataloader_label_val, preprocess_input_paligemma)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_error(train_errors_kd_paligemma, val_errors_kd_paligemma)",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
