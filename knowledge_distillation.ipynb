{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports & Setup"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ktdrhWnZ87XJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import ast\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import helpers\n",
    "import soft_prompting\n",
    "import importlib\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(soft_prompting)"
   ],
   "metadata": {
    "id": "L6TP2Hzr87XM",
    "outputId": "2c09cfa8-ab7b-402a-de07-099e0163bc85",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# CONSTANTS\n",
    "NUM_EPOCHS_FT = 100\n",
    "NUM_EPOCHS_KD = 100\n",
    "BATCH_SIZE = 32"
   ],
   "metadata": {
    "id": "uvM8QDGl87XP"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Data and preprocess it"
   ],
   "metadata": {
    "collapsed": false,
    "id": "pNEtAiGe87XP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### train data\n",
    "# data with label and image data\n",
    "df_train_label = pd.DataFrame(load_dataset('derek-thomas/ScienceQA', split='train'))\n",
    "df_train_label = df_train_label[df_train_label['solution'] != ''].reset_index()\n",
    "df_train_label['input'] = df_train_label.apply(lambda row: helpers.build_prompt(row)[0], axis=1)\n",
    "df_train_label[['index', 'input', 'answer', 'explanation', 'image']] = df_train_label[['index', 'input', 'answer', 'solution', 'image']]\n",
    "\n",
    "# data from Gemini for KD\n",
    "df_train_gemini = pd.read_csv('gemini_1_5_flash_output_train.csv', sep=\"\\t\")[['index', 'input', 'answer', 'explanation']]\n",
    "df_train_gemini = pd.merge(df_train_gemini, df_train_label[['index', 'image']], on='index')"
   ],
   "metadata": {
    "id": "gjuLrTbq87XQ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "### val data\n",
    "df_val = pd.DataFrame(load_dataset('derek-thomas/ScienceQA', split='validation'))"
   ],
   "metadata": {
    "id": "izTEvl6i87XR"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "### Build Dataset class\n",
    "class SoftPromptingDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.data = self.__preprocess_data(df)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return sample\n",
    "\n",
    "    def __preprocess_data(self, data):\n",
    "        data['input'] = data.apply(lambda row: self.tokenizer.encode(row['input'], return_tensors='pt'), axis=1)\n",
    "        return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions for model training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "NStdSFIf87XS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train(dataloader_train, dataloader_val):\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "    for epoch in tqdm(range(NUM_EPOCHS_FT)):\n",
    "        error = 0\n",
    "        num_samples = 0\n",
    "        for input, answer, explanation, image in dataloader_train:\n",
    "            pass\n",
    "            # forward\n",
    "            # loss = ...\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            # error += loss.item() * X.size(0)\n",
    "            # num_samples += X.size(0)\n",
    "        error /= num_samples\n",
    "        print(f'Error after epoch {epoch}: {error}')\n",
    "        train_errors.append((epoch, error))\n",
    "        if epoch % 10:\n",
    "            val_error = 0\n",
    "            num_samples\n",
    "            for input, answer, explanation, image in dataloader_val:\n",
    "                pass\n",
    "                # forward\n",
    "                # loss = ...\n",
    "                # val_error += loss.item() * X.size(0)\n",
    "                # num_samples += X.size(0)\n",
    "            val_error /= num_samples\n",
    "            print(f'Validation error after epoch {epoch}: {val_error}')\n",
    "            val_errors.append((epoch, val_error))\n",
    "    return train_errors_ft, val_error"
   ],
   "metadata": {
    "id": "mBOk6eSR87XT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def visualize_error(train_errors, val_errors):\n",
    "    plt.plot(zip(*train_errors), label=\"Train Error\", marker=\"o\", linestyle=\"-\")\n",
    "    plt.plot(zip(*val_errors), label=\"Train Error\", marker=\"o\", linestyle=\"-\")\n",
    "    plt.title(\"Train and Validation Error over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "yKhEnvHx87XU"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Soft prompting using labels"
   ],
   "metadata": {
    "collapsed": false,
    "id": "eoPYPMBq87XU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"Qwen/Qwen2.5-Coder-0.5B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_fine_tuned = soft_prompting.MultimodalSoftPrompting.from_pretrained(model)\n",
    "# DataLoader for train data\n",
    "dataset_label_train = SoftPromptingDataset(df_train_label, tokenizer)\n",
    "dataloader_label_train=DataLoader(dataset_label_train, batch_size=32, shuffle=True)\n",
    "# DataLoader for val data\n",
    "dataset_label_val = SoftPromptingDataset(df_val, model_fine_tuned)\n",
    "dataloader_label_val=DataLoader(dataset_label_val, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "id": "Tcw_Fj0R87XV"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_errors_ft, val_errors_ft = train(dataloader_label_train, dataloader_label_val)"
   ],
   "metadata": {
    "id": "bBY-hEz687XV"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_error(train_errors_ft, val_errors_ft)"
   ],
   "metadata": {
    "id": "weNRYFe787XX"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Knowledge Distillation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "qw5SW6bP87XY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = None # ToDo\n",
    "model_knowledge_distillation = soft_prompting.MultimodalSoftPrompting.from_pretrained(model)\n",
    "# DataLoader for train data\n",
    "dataset_gemini_train = SoftPromptingDataset(df_train_gemini, model_fine_tuned)\n",
    "dataloader_gemini_train=DataLoader(dataset_gemini_train, batch_size=32, shuffle=True)\n",
    "# DataLoader for val data\n",
    "dataset_gemini_val = SoftPromptingDataset(df_val, model_fine_tuned)\n",
    "dataloader_gemini_val=DataLoader(dataset_gemini_val, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "id": "ZV4PV0m087XY"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_errors_kd, val_errors_kd = train(dataset_gemini_train, dataloader_gemini_train)"
   ],
   "metadata": {
    "id": "ZP04R7VX87XZ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_error(train_errors_kd, val_errors_kd)"
   ],
   "metadata": {
    "id": "jJn7pB2b87XZ"
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
