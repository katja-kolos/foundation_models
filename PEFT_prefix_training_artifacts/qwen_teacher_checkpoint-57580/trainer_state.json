{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 57580,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1736714136853074,
      "grad_norm": 1.9217464923858643,
      "learning_rate": 1.9826328586314695e-05,
      "loss": 8.0515,
      "step": 500
    },
    {
      "epoch": 0.3473428273706148,
      "grad_norm": 1.3895334005355835,
      "learning_rate": 1.9652657172629385e-05,
      "loss": 5.9237,
      "step": 1000
    },
    {
      "epoch": 0.5210142410559222,
      "grad_norm": 2.827218532562256,
      "learning_rate": 1.947898575894408e-05,
      "loss": 4.3801,
      "step": 1500
    },
    {
      "epoch": 0.6946856547412296,
      "grad_norm": 3.717405319213867,
      "learning_rate": 1.9305314345258772e-05,
      "loss": 3.3728,
      "step": 2000
    },
    {
      "epoch": 0.868357068426537,
      "grad_norm": 2.022958755493164,
      "learning_rate": 1.9131642931573466e-05,
      "loss": 2.791,
      "step": 2500
    },
    {
      "epoch": 1.0420284821118444,
      "grad_norm": 1.2313168048858643,
      "learning_rate": 1.8957971517888156e-05,
      "loss": 2.3507,
      "step": 3000
    },
    {
      "epoch": 1.2156998957971519,
      "grad_norm": 0.7471120357513428,
      "learning_rate": 1.878430010420285e-05,
      "loss": 2.0646,
      "step": 3500
    },
    {
      "epoch": 1.3893713094824591,
      "grad_norm": 1.5415772199630737,
      "learning_rate": 1.8610628690517543e-05,
      "loss": 1.8253,
      "step": 4000
    },
    {
      "epoch": 1.5630427231677666,
      "grad_norm": 0.8236997127532959,
      "learning_rate": 1.8436957276832233e-05,
      "loss": 1.6991,
      "step": 4500
    },
    {
      "epoch": 1.7367141368530739,
      "grad_norm": 0.9197290539741516,
      "learning_rate": 1.8263285863146927e-05,
      "loss": 1.5647,
      "step": 5000
    },
    {
      "epoch": 1.9103855505383813,
      "grad_norm": 0.49742865562438965,
      "learning_rate": 1.808961444946162e-05,
      "loss": 1.4442,
      "step": 5500
    },
    {
      "epoch": 2.084056964223689,
      "grad_norm": 0.7717546820640564,
      "learning_rate": 1.7915943035776314e-05,
      "loss": 1.4103,
      "step": 6000
    },
    {
      "epoch": 2.2577283779089963,
      "grad_norm": 0.5500514507293701,
      "learning_rate": 1.7742271622091004e-05,
      "loss": 1.3858,
      "step": 6500
    },
    {
      "epoch": 2.4313997915943037,
      "grad_norm": 0.7388526797294617,
      "learning_rate": 1.7568600208405697e-05,
      "loss": 1.3611,
      "step": 7000
    },
    {
      "epoch": 2.605071205279611,
      "grad_norm": 1.1624287366867065,
      "learning_rate": 1.739492879472039e-05,
      "loss": 1.3385,
      "step": 7500
    },
    {
      "epoch": 2.7787426189649183,
      "grad_norm": 0.7171700596809387,
      "learning_rate": 1.7221257381035084e-05,
      "loss": 1.3235,
      "step": 8000
    },
    {
      "epoch": 2.9524140326502257,
      "grad_norm": 0.6776682734489441,
      "learning_rate": 1.7047585967349774e-05,
      "loss": 1.2808,
      "step": 8500
    },
    {
      "epoch": 3.126085446335533,
      "grad_norm": 0.9419641494750977,
      "learning_rate": 1.6873914553664468e-05,
      "loss": 1.2502,
      "step": 9000
    },
    {
      "epoch": 3.2997568600208407,
      "grad_norm": 0.8013466000556946,
      "learning_rate": 1.670024313997916e-05,
      "loss": 1.2427,
      "step": 9500
    },
    {
      "epoch": 3.473428273706148,
      "grad_norm": 0.8253083825111389,
      "learning_rate": 1.6526571726293855e-05,
      "loss": 1.2333,
      "step": 10000
    },
    {
      "epoch": 3.6470996873914556,
      "grad_norm": 0.9524887204170227,
      "learning_rate": 1.6352900312608545e-05,
      "loss": 1.2007,
      "step": 10500
    },
    {
      "epoch": 3.8207711010767627,
      "grad_norm": 0.7508648633956909,
      "learning_rate": 1.617922889892324e-05,
      "loss": 1.1723,
      "step": 11000
    },
    {
      "epoch": 3.99444251476207,
      "grad_norm": 0.9482079744338989,
      "learning_rate": 1.6005557485237932e-05,
      "loss": 1.1813,
      "step": 11500
    },
    {
      "epoch": 4.168113928447378,
      "grad_norm": 0.3461726903915405,
      "learning_rate": 1.5831886071552625e-05,
      "loss": 1.1696,
      "step": 12000
    },
    {
      "epoch": 4.341785342132685,
      "grad_norm": 0.45440873503685,
      "learning_rate": 1.5658214657867316e-05,
      "loss": 1.1304,
      "step": 12500
    },
    {
      "epoch": 4.5154567558179926,
      "grad_norm": 1.387912392616272,
      "learning_rate": 1.548454324418201e-05,
      "loss": 1.1104,
      "step": 13000
    },
    {
      "epoch": 4.6891281695033,
      "grad_norm": 0.5128754377365112,
      "learning_rate": 1.53108718304967e-05,
      "loss": 1.1583,
      "step": 13500
    },
    {
      "epoch": 4.8627995831886075,
      "grad_norm": 0.22427134215831757,
      "learning_rate": 1.5137200416811394e-05,
      "loss": 1.1498,
      "step": 14000
    },
    {
      "epoch": 5.0364709968739145,
      "grad_norm": 0.3403548300266266,
      "learning_rate": 1.4963529003126088e-05,
      "loss": 1.1257,
      "step": 14500
    },
    {
      "epoch": 5.210142410559222,
      "grad_norm": 0.6606717109680176,
      "learning_rate": 1.478985758944078e-05,
      "loss": 1.0947,
      "step": 15000
    },
    {
      "epoch": 5.3838138242445295,
      "grad_norm": 0.3384154736995697,
      "learning_rate": 1.4616186175755472e-05,
      "loss": 1.1187,
      "step": 15500
    },
    {
      "epoch": 5.5574852379298365,
      "grad_norm": 0.24147731065750122,
      "learning_rate": 1.4442514762070163e-05,
      "loss": 1.0787,
      "step": 16000
    },
    {
      "epoch": 5.731156651615144,
      "grad_norm": 0.22832000255584717,
      "learning_rate": 1.4268843348384857e-05,
      "loss": 1.0926,
      "step": 16500
    },
    {
      "epoch": 5.9048280653004515,
      "grad_norm": 0.3854970335960388,
      "learning_rate": 1.409517193469955e-05,
      "loss": 1.1008,
      "step": 17000
    },
    {
      "epoch": 6.078499478985759,
      "grad_norm": 0.9641510844230652,
      "learning_rate": 1.3921500521014242e-05,
      "loss": 1.071,
      "step": 17500
    },
    {
      "epoch": 6.252170892671066,
      "grad_norm": 1.1078330278396606,
      "learning_rate": 1.3747829107328934e-05,
      "loss": 1.0769,
      "step": 18000
    },
    {
      "epoch": 6.425842306356373,
      "grad_norm": 0.725634753704071,
      "learning_rate": 1.3574157693643627e-05,
      "loss": 1.06,
      "step": 18500
    },
    {
      "epoch": 6.599513720041681,
      "grad_norm": 0.31764131784439087,
      "learning_rate": 1.3400486279958321e-05,
      "loss": 1.0812,
      "step": 19000
    },
    {
      "epoch": 6.773185133726988,
      "grad_norm": 0.40554091334342957,
      "learning_rate": 1.3226814866273013e-05,
      "loss": 1.0628,
      "step": 19500
    },
    {
      "epoch": 6.946856547412296,
      "grad_norm": 0.22817979753017426,
      "learning_rate": 1.3053143452587705e-05,
      "loss": 1.0664,
      "step": 20000
    },
    {
      "epoch": 7.120527961097603,
      "grad_norm": 0.3196024000644684,
      "learning_rate": 1.2879472038902398e-05,
      "loss": 1.0454,
      "step": 20500
    },
    {
      "epoch": 7.29419937478291,
      "grad_norm": 0.445199191570282,
      "learning_rate": 1.270580062521709e-05,
      "loss": 1.0884,
      "step": 21000
    },
    {
      "epoch": 7.467870788468218,
      "grad_norm": 0.3724387586116791,
      "learning_rate": 1.2532129211531783e-05,
      "loss": 1.0538,
      "step": 21500
    },
    {
      "epoch": 7.641542202153525,
      "grad_norm": 0.626727283000946,
      "learning_rate": 1.2358457797846475e-05,
      "loss": 1.0663,
      "step": 22000
    },
    {
      "epoch": 7.815213615838833,
      "grad_norm": 0.520767867565155,
      "learning_rate": 1.2184786384161169e-05,
      "loss": 1.0427,
      "step": 22500
    },
    {
      "epoch": 7.98888502952414,
      "grad_norm": 0.3774612545967102,
      "learning_rate": 1.201111497047586e-05,
      "loss": 1.0394,
      "step": 23000
    },
    {
      "epoch": 8.162556443209448,
      "grad_norm": 0.41138386726379395,
      "learning_rate": 1.1837443556790554e-05,
      "loss": 1.0464,
      "step": 23500
    },
    {
      "epoch": 8.336227856894755,
      "grad_norm": 0.3353705406188965,
      "learning_rate": 1.1663772143105246e-05,
      "loss": 1.0353,
      "step": 24000
    },
    {
      "epoch": 8.509899270580062,
      "grad_norm": 0.5326685905456543,
      "learning_rate": 1.1490100729419938e-05,
      "loss": 1.0237,
      "step": 24500
    },
    {
      "epoch": 8.68357068426537,
      "grad_norm": 0.228002667427063,
      "learning_rate": 1.1316429315734631e-05,
      "loss": 1.0515,
      "step": 25000
    },
    {
      "epoch": 8.857242097950678,
      "grad_norm": 4.421810626983643,
      "learning_rate": 1.1142757902049323e-05,
      "loss": 1.0541,
      "step": 25500
    },
    {
      "epoch": 9.030913511635985,
      "grad_norm": 0.9187568426132202,
      "learning_rate": 1.0969086488364016e-05,
      "loss": 1.0289,
      "step": 26000
    },
    {
      "epoch": 9.204584925321292,
      "grad_norm": 0.22756943106651306,
      "learning_rate": 1.0795415074678708e-05,
      "loss": 1.0368,
      "step": 26500
    },
    {
      "epoch": 9.3782563390066,
      "grad_norm": 0.7979837656021118,
      "learning_rate": 1.0621743660993402e-05,
      "loss": 0.9876,
      "step": 27000
    },
    {
      "epoch": 9.551927752691906,
      "grad_norm": 0.21530987322330475,
      "learning_rate": 1.0448072247308094e-05,
      "loss": 1.0537,
      "step": 27500
    },
    {
      "epoch": 9.725599166377215,
      "grad_norm": 0.21584008634090424,
      "learning_rate": 1.0274400833622787e-05,
      "loss": 1.038,
      "step": 28000
    },
    {
      "epoch": 9.899270580062522,
      "grad_norm": 0.25540590286254883,
      "learning_rate": 1.0100729419937479e-05,
      "loss": 0.9912,
      "step": 28500
    },
    {
      "epoch": 10.072941993747829,
      "grad_norm": 0.46315544843673706,
      "learning_rate": 9.92705800625217e-06,
      "loss": 1.0193,
      "step": 29000
    },
    {
      "epoch": 10.246613407433136,
      "grad_norm": 0.8290821313858032,
      "learning_rate": 9.753386592566864e-06,
      "loss": 1.0098,
      "step": 29500
    },
    {
      "epoch": 10.420284821118443,
      "grad_norm": 3.099485158920288,
      "learning_rate": 9.579715178881556e-06,
      "loss": 1.0057,
      "step": 30000
    },
    {
      "epoch": 10.593956234803752,
      "grad_norm": 0.16912128031253815,
      "learning_rate": 9.40604376519625e-06,
      "loss": 1.0069,
      "step": 30500
    },
    {
      "epoch": 10.767627648489059,
      "grad_norm": 0.20106786489486694,
      "learning_rate": 9.232372351510941e-06,
      "loss": 1.0173,
      "step": 31000
    },
    {
      "epoch": 10.941299062174366,
      "grad_norm": 0.32682928442955017,
      "learning_rate": 9.058700937825635e-06,
      "loss": 1.013,
      "step": 31500
    },
    {
      "epoch": 11.114970475859673,
      "grad_norm": 0.3981979191303253,
      "learning_rate": 8.885029524140327e-06,
      "loss": 1.0027,
      "step": 32000
    },
    {
      "epoch": 11.28864188954498,
      "grad_norm": 0.2983350157737732,
      "learning_rate": 8.711358110455018e-06,
      "loss": 0.9915,
      "step": 32500
    },
    {
      "epoch": 11.462313303230289,
      "grad_norm": 0.2208677977323532,
      "learning_rate": 8.537686696769712e-06,
      "loss": 1.0154,
      "step": 33000
    },
    {
      "epoch": 11.635984716915596,
      "grad_norm": 0.4589594006538391,
      "learning_rate": 8.364015283084404e-06,
      "loss": 1.0082,
      "step": 33500
    },
    {
      "epoch": 11.809656130600903,
      "grad_norm": 0.4164861738681793,
      "learning_rate": 8.190343869399097e-06,
      "loss": 1.0035,
      "step": 34000
    },
    {
      "epoch": 11.98332754428621,
      "grad_norm": 0.23232725262641907,
      "learning_rate": 8.016672455713789e-06,
      "loss": 1.0,
      "step": 34500
    },
    {
      "epoch": 12.156998957971519,
      "grad_norm": 0.2928732931613922,
      "learning_rate": 7.843001042028483e-06,
      "loss": 1.016,
      "step": 35000
    },
    {
      "epoch": 12.330670371656826,
      "grad_norm": 0.2626015543937683,
      "learning_rate": 7.669329628343174e-06,
      "loss": 0.9929,
      "step": 35500
    },
    {
      "epoch": 12.504341785342133,
      "grad_norm": 0.3522297739982605,
      "learning_rate": 7.495658214657868e-06,
      "loss": 1.0012,
      "step": 36000
    },
    {
      "epoch": 12.67801319902744,
      "grad_norm": 0.5194070339202881,
      "learning_rate": 7.321986800972561e-06,
      "loss": 1.0041,
      "step": 36500
    },
    {
      "epoch": 12.851684612712747,
      "grad_norm": 0.6006246209144592,
      "learning_rate": 7.148315387287253e-06,
      "loss": 0.9858,
      "step": 37000
    },
    {
      "epoch": 13.025356026398056,
      "grad_norm": 1.5652446746826172,
      "learning_rate": 6.974643973601946e-06,
      "loss": 1.0255,
      "step": 37500
    },
    {
      "epoch": 13.199027440083363,
      "grad_norm": 0.2943320870399475,
      "learning_rate": 6.800972559916639e-06,
      "loss": 1.0078,
      "step": 38000
    },
    {
      "epoch": 13.37269885376867,
      "grad_norm": 0.609113335609436,
      "learning_rate": 6.62730114623133e-06,
      "loss": 0.9937,
      "step": 38500
    },
    {
      "epoch": 13.546370267453977,
      "grad_norm": 0.2700691223144531,
      "learning_rate": 6.453629732546024e-06,
      "loss": 0.9713,
      "step": 39000
    },
    {
      "epoch": 13.720041681139284,
      "grad_norm": 0.16645684838294983,
      "learning_rate": 6.279958318860716e-06,
      "loss": 0.9835,
      "step": 39500
    },
    {
      "epoch": 13.893713094824593,
      "grad_norm": 0.37904664874076843,
      "learning_rate": 6.106286905175408e-06,
      "loss": 1.0109,
      "step": 40000
    },
    {
      "epoch": 14.0673845085099,
      "grad_norm": 0.4065861999988556,
      "learning_rate": 5.932615491490101e-06,
      "loss": 1.0261,
      "step": 40500
    },
    {
      "epoch": 14.241055922195207,
      "grad_norm": 0.5711956024169922,
      "learning_rate": 5.758944077804794e-06,
      "loss": 0.9911,
      "step": 41000
    },
    {
      "epoch": 14.414727335880514,
      "grad_norm": 0.3371492326259613,
      "learning_rate": 5.585272664119486e-06,
      "loss": 1.0152,
      "step": 41500
    },
    {
      "epoch": 14.58839874956582,
      "grad_norm": 0.2693313658237457,
      "learning_rate": 5.411601250434179e-06,
      "loss": 0.9788,
      "step": 42000
    },
    {
      "epoch": 14.76207016325113,
      "grad_norm": 0.5235392451286316,
      "learning_rate": 5.237929836748872e-06,
      "loss": 0.9716,
      "step": 42500
    },
    {
      "epoch": 14.935741576936437,
      "grad_norm": 0.17084453999996185,
      "learning_rate": 5.0642584230635635e-06,
      "loss": 1.0139,
      "step": 43000
    },
    {
      "epoch": 15.109412990621744,
      "grad_norm": 0.2408783733844757,
      "learning_rate": 4.890587009378256e-06,
      "loss": 0.9664,
      "step": 43500
    },
    {
      "epoch": 15.28308440430705,
      "grad_norm": 0.30759039521217346,
      "learning_rate": 4.716915595692949e-06,
      "loss": 0.969,
      "step": 44000
    },
    {
      "epoch": 15.456755817992358,
      "grad_norm": 0.26930108666419983,
      "learning_rate": 4.5432441820076414e-06,
      "loss": 0.9657,
      "step": 44500
    },
    {
      "epoch": 15.630427231677666,
      "grad_norm": 0.13576385378837585,
      "learning_rate": 4.369572768322334e-06,
      "loss": 0.9926,
      "step": 45000
    },
    {
      "epoch": 15.804098645362973,
      "grad_norm": 0.3004165589809418,
      "learning_rate": 4.195901354637027e-06,
      "loss": 0.9752,
      "step": 45500
    },
    {
      "epoch": 15.97777005904828,
      "grad_norm": 0.8606073260307312,
      "learning_rate": 4.022229940951719e-06,
      "loss": 1.0118,
      "step": 46000
    },
    {
      "epoch": 16.151441472733588,
      "grad_norm": 0.2221318483352661,
      "learning_rate": 3.848558527266412e-06,
      "loss": 0.9857,
      "step": 46500
    },
    {
      "epoch": 16.325112886418896,
      "grad_norm": 1.2468886375427246,
      "learning_rate": 3.6748871135811047e-06,
      "loss": 0.9829,
      "step": 47000
    },
    {
      "epoch": 16.4987843001042,
      "grad_norm": 0.16434991359710693,
      "learning_rate": 3.5012156998957974e-06,
      "loss": 0.9942,
      "step": 47500
    },
    {
      "epoch": 16.67245571378951,
      "grad_norm": 0.44164329767227173,
      "learning_rate": 3.32754428621049e-06,
      "loss": 0.9813,
      "step": 48000
    },
    {
      "epoch": 16.84612712747482,
      "grad_norm": 0.44350171089172363,
      "learning_rate": 3.1538728725251827e-06,
      "loss": 1.002,
      "step": 48500
    },
    {
      "epoch": 17.019798541160124,
      "grad_norm": 0.6558461785316467,
      "learning_rate": 2.9802014588398754e-06,
      "loss": 0.9973,
      "step": 49000
    },
    {
      "epoch": 17.193469954845433,
      "grad_norm": 0.3352890908718109,
      "learning_rate": 2.806530045154568e-06,
      "loss": 0.987,
      "step": 49500
    },
    {
      "epoch": 17.36714136853074,
      "grad_norm": 0.39665016531944275,
      "learning_rate": 2.6328586314692607e-06,
      "loss": 0.9873,
      "step": 50000
    },
    {
      "epoch": 17.540812782216047,
      "grad_norm": 0.5108110308647156,
      "learning_rate": 2.459187217783953e-06,
      "loss": 0.9483,
      "step": 50500
    },
    {
      "epoch": 17.714484195901356,
      "grad_norm": 0.2114495038986206,
      "learning_rate": 2.2855158040986456e-06,
      "loss": 0.9821,
      "step": 51000
    },
    {
      "epoch": 17.88815560958666,
      "grad_norm": 0.41937750577926636,
      "learning_rate": 2.1118443904133382e-06,
      "loss": 0.9722,
      "step": 51500
    },
    {
      "epoch": 18.06182702327197,
      "grad_norm": 0.9314575791358948,
      "learning_rate": 1.938172976728031e-06,
      "loss": 1.024,
      "step": 52000
    },
    {
      "epoch": 18.235498436957275,
      "grad_norm": 0.32793179154396057,
      "learning_rate": 1.7645015630427233e-06,
      "loss": 0.9552,
      "step": 52500
    },
    {
      "epoch": 18.409169850642584,
      "grad_norm": 0.1478186398744583,
      "learning_rate": 1.590830149357416e-06,
      "loss": 0.97,
      "step": 53000
    },
    {
      "epoch": 18.582841264327893,
      "grad_norm": 0.35703185200691223,
      "learning_rate": 1.4171587356721085e-06,
      "loss": 0.9915,
      "step": 53500
    },
    {
      "epoch": 18.7565126780132,
      "grad_norm": 0.5055964589118958,
      "learning_rate": 1.2434873219868011e-06,
      "loss": 0.9972,
      "step": 54000
    },
    {
      "epoch": 18.930184091698507,
      "grad_norm": 0.8309809565544128,
      "learning_rate": 1.0698159083014936e-06,
      "loss": 0.9925,
      "step": 54500
    },
    {
      "epoch": 19.103855505383812,
      "grad_norm": 0.19511359930038452,
      "learning_rate": 8.961444946161862e-07,
      "loss": 0.9853,
      "step": 55000
    },
    {
      "epoch": 19.27752691906912,
      "grad_norm": 0.22212286293506622,
      "learning_rate": 7.224730809308789e-07,
      "loss": 0.9762,
      "step": 55500
    },
    {
      "epoch": 19.45119833275443,
      "grad_norm": 0.4183025062084198,
      "learning_rate": 5.488016672455714e-07,
      "loss": 1.0086,
      "step": 56000
    },
    {
      "epoch": 19.624869746439735,
      "grad_norm": 0.4464923143386841,
      "learning_rate": 3.7513025356026403e-07,
      "loss": 0.9991,
      "step": 56500
    },
    {
      "epoch": 19.798541160125044,
      "grad_norm": 0.41367197036743164,
      "learning_rate": 2.014588398749566e-07,
      "loss": 0.966,
      "step": 57000
    },
    {
      "epoch": 19.97221257381035,
      "grad_norm": 0.2643269896507263,
      "learning_rate": 2.7787426189649184e-08,
      "loss": 0.9841,
      "step": 57500
    }
  ],
  "logging_steps": 500,
  "max_steps": 57580,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4001613939261778e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
